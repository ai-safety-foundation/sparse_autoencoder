{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ai-safety-foundation/sparse_autoencoder/blob/main/docs/content/demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Training Demo\n",
    "\n",
    "This is a quick start demo to get training a SAE right away. All you need to do is choose a few\n",
    "hyperparameters (like the model to train on), and then set it off.\n",
    "By default it replicates Neel Nanda's\n",
    "[comment on the Anthropic dictionary learning\n",
    "paper](https://transformer-circuits.pub/2023/monosemantic-features/index.html#comment-nanda)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab  # noqa: F401 # type: ignore\n",
    "\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "\n",
    "#  Install if in Colab\n",
    "if in_colab:\n",
    "    %pip install sparse_autoencoder transformer_lens transformers wandb\n",
    "\n",
    "# Otherwise enable hot reloading in dev mode\n",
    "if not in_colab:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sparse_autoencoder import (\n",
    "    ActivationResamplerHyperparameters,\n",
    "    Hyperparameters,\n",
    "    LossHyperparameters,\n",
    "    Method,\n",
    "    OptimizerHyperparameters,\n",
    "    Parameter,\n",
    "    SourceDataHyperparameters,\n",
    "    SourceModelHyperparameters,\n",
    "    sweep,\n",
    "    SweepConfig,\n",
    ")\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"demo.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize any hyperparameters you want below (by default we're sweeping over l1 coefficient and\n",
    "learning rate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SourceModelHyperparameters.__init__() got an unexpected keyword argument 'hook_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m sweep_config \u001b[38;5;241m=\u001b[39m SweepConfig(\n\u001b[1;32m      2\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mHyperparameters(\n\u001b[1;32m      3\u001b[0m         activation_resampler\u001b[38;5;241m=\u001b[39mActivationResamplerHyperparameters(\n\u001b[1;32m      4\u001b[0m             threshold_is_dead_portion_fires\u001b[38;5;241m=\u001b[39mParameter(\u001b[38;5;241m1e-6\u001b[39m),\n\u001b[1;32m      5\u001b[0m         ),\n\u001b[1;32m      6\u001b[0m         loss\u001b[38;5;241m=\u001b[39mLossHyperparameters(\n\u001b[1;32m      7\u001b[0m             l1_coefficient\u001b[38;5;241m=\u001b[39mParameter(\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4e-3\u001b[39m),\n\u001b[1;32m      8\u001b[0m         ),\n\u001b[1;32m      9\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mOptimizerHyperparameters(\n\u001b[1;32m     10\u001b[0m             lr\u001b[38;5;241m=\u001b[39mParameter(\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m),\n\u001b[1;32m     11\u001b[0m         ),\n\u001b[0;32m---> 12\u001b[0m         source_model\u001b[38;5;241m=\u001b[39m\u001b[43mSourceModelHyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgelu-2l\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp_out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhook_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhook_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     18\u001b[0m         source_data\u001b[38;5;241m=\u001b[39mSourceDataHyperparameters(\n\u001b[1;32m     19\u001b[0m             dataset_path\u001b[38;5;241m=\u001b[39mParameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeelNanda/c4-code-tokenized-2b\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     20\u001b[0m         ),\n\u001b[1;32m     21\u001b[0m     ),\n\u001b[1;32m     22\u001b[0m     method\u001b[38;5;241m=\u001b[39mMethod\u001b[38;5;241m.\u001b[39mRANDOM,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m sweep_config\n",
      "\u001b[0;31mTypeError\u001b[0m: SourceModelHyperparameters.__init__() got an unexpected keyword argument 'hook_layer'"
     ]
    }
   ],
   "source": [
    "sweep_config = SweepConfig(\n",
    "    parameters=Hyperparameters(\n",
    "        activation_resampler=ActivationResamplerHyperparameters(\n",
    "            threshold_is_dead_portion_fires=Parameter(1e-6),\n",
    "        ),\n",
    "        loss=LossHyperparameters(\n",
    "            l1_coefficient=Parameter(max=1e-2, min=4e-3),\n",
    "        ),\n",
    "        optimizer=OptimizerHyperparameters(\n",
    "            lr=Parameter(max=1e-3, min=1e-5),\n",
    "        ),\n",
    "        source_model=SourceModelHyperparameters(\n",
    "            name=Parameter(\"gelu-2l\"),\n",
    "            cache_names=Parameter([\"blocks.0.hook_mlp_out\", \"blocks.1.hook_mlp_out\"]),\n",
    "            hook_dimension=Parameter(512),\n",
    "        ),\n",
    "        source_data=SourceDataHyperparameters(\n",
    "            dataset_path=Parameter(\"NeelNanda/c4-code-tokenized-2b\"),\n",
    "        ),\n",
    "    ),\n",
    "    method=Method.RANDOM,\n",
    ")\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep(sweep_config=sweep_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31186ba1239ad81afeb3c631b4833e71f34259d3b92eebb37a9091b916e08620"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
