{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Autoencoder Training Demo\n",
    "\n",
    "This demo trains a sparse autoencoder on activations from a Tiny Stories 1M model.\n",
    "\n",
    "To do this we setup a *source model* (the TinyStories model) that we want to generate activations\n",
    "from, along with a *source dataset* of prompts to help generate these activations.\n",
    "\n",
    "We also setup a *sparse autoencoder model* which we'll train on these generated activations, to\n",
    "learn a sparse representation of them in higher dimensional space.\n",
    "\n",
    "Finally we'll wrap this all together in a *pipeline*, which alternates between generating\n",
    "activations (storing them in ram), and training the SAE on said activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "import wandb\n",
    "\n",
    "from sparse_autoencoder import SparseAutoencoder\n",
    "from sparse_autoencoder.activation_resampler import ActivationResampler\n",
    "from sparse_autoencoder.loss.learned_activations_l1 import LearnedActivationsL1Loss\n",
    "from sparse_autoencoder.loss.mse_reconstruction_loss import MSEReconstructionLoss\n",
    "from sparse_autoencoder.loss.reducer import LossReducer\n",
    "from sparse_autoencoder.optimizer.adam_with_reset import AdamWithReset\n",
    "from sparse_autoencoder.source_data.text_dataset import GenericTextDataset\n",
    "from sparse_autoencoder.train.pipeline import Pipeline\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")  # You will need a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way this library works is that you can define your own hyper-parameters and then setup the\n",
    "underlying components with them. This is extremely flexible, but to help you get started we've\n",
    "included some common ones below along with some sensible defaults. You can also easily sweep through\n",
    "multiple hyperparameters with `wandb.sweep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    # Expansion factor is the number of features in the sparse representation, relative to the\n",
    "    # number of features in the original MLP layer. The original paper experimented with 1x to 256x,\n",
    "    # and we have found that 4x is a good starting point.\n",
    "    \"expansion_factor\": 4,\n",
    "    # L1 coefficient is the coefficient of the L1 regularization term (used to encourage sparsity).\n",
    "    \"l1_coefficient\": 0.001,\n",
    "    # Adam parameters (set to the default ones here)\n",
    "    \"lr\": 0.001,\n",
    "    \"adam_beta_1\": 0.9,\n",
    "    \"adam_beta_2\": 0.999,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"adam_weight_decay\": 0.0,\n",
    "    # Batch sizes\n",
    "    \"train_batch_size\": 8192,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source model is just a [TransformerLens](https://github.com/neelnanda-io/TransformerLens) model\n",
    "(see [here](https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "for a full list of supported models).\n",
    "\n",
    "In this example we're training a sparse autoencoder on the activations from the first MLP layer, so\n",
    "we'll also get some details about that hook point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1M into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Source: tiny-stories-1M, Hook: blocks.0.mlp.hook_post, Features: 256'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source model setup with TransformerLens\n",
    "src_model_name = \"tiny-stories-1M\"\n",
    "src_model = HookedTransformer.from_pretrained(src_model_name, dtype=\"float32\")\n",
    "\n",
    "# Details about the activations we'll train the sparse autoencoder on\n",
    "src_model_activation_hook_point = \"blocks.0.mlp.hook_post\"\n",
    "src_model_activation_layer = 0\n",
    "src_d_mlp: int = src_model.cfg.d_mlp  # type: ignore (TransformerLens typing is currently broken)\n",
    "\n",
    "f\"Source: {src_model_name}, Hook: {src_model_activation_hook_point}, Features: {src_d_mlp}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then setup the sparse autoencoder. The default model (`SparseAutoencoder`) is setup as per\n",
    "the original Anthropic paper [Towards Monosemanticity: Decomposing Language Models With Dictionary\n",
    "Learning ](https://transformer-circuits.pub/2023/monosemantic-features/index.html).\n",
    "\n",
    "However it's just a standard PyTorch model, so you can create your own model instead if you want to\n",
    "use a different architecture. To do this you just need to extend the `AbstractAutoencoder`, and\n",
    "optionally the underlying `AbstractEncoder`, `AbstractDecoder` and `AbstractOuterBias`. See these\n",
    "classes (which are fully documented) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (_pre_encoder_bias): TiedBias(position=pre_encoder)\n",
       "  (_encoder): LinearEncoder(\n",
       "    in_features=256, out_features=1024\n",
       "    (activation_function): ReLU()\n",
       "  )\n",
       "  (_decoder): UnitNormDecoder(in_features=1024, out_features=256)\n",
       "  (_post_decoder_bias): TiedBias(position=post_decoder)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion_factor = hyperparameters[\"expansion_factor\"]\n",
    "autoencoder = SparseAutoencoder(\n",
    "    n_input_features=src_d_mlp,  # size of the activations we are autoencoding\n",
    "    n_learned_features=int(src_d_mlp * expansion_factor),  # size of SAE\n",
    "    geometric_median_dataset=torch.zeros(src_d_mlp),  # this is used to initialize the tied bias\n",
    ").to(device)\n",
    "autoencoder  # Print the model (it's pretty straightforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also want to setup an Optimizer and Loss function. In this case we'll also use the standard\n",
    "approach from the original Anthropic paper. However you can create your own loss functions and\n",
    "optimizers by extending `AbstractLoss` and `AbstractOptimizerWithReset` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LossReducer(\n",
       "  (0): LearnedActivationsL1Loss(l1_coefficient=0.001)\n",
       "  (1): MSEReconstructionLoss()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a loss reducer, which simply adds up the losses from the underlying loss functions.\n",
    "loss = LossReducer(\n",
    "    LearnedActivationsL1Loss(\n",
    "        l1_coefficient=hyperparameters[\"l1_coefficient\"],\n",
    "    ),\n",
    "    MSEReconstructionLoss(),\n",
    ")\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamWithReset (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamWithReset(\n",
    "    params=autoencoder.parameters(),\n",
    "    named_parameters=autoencoder.named_parameters(),\n",
    "    lr=hyperparameters[\"lr\"],\n",
    "    betas=(hyperparameters[\"adam_beta_1\"], hyperparameters[\"adam_beta_2\"]),\n",
    "    eps=hyperparameters[\"adam_epsilon\"],\n",
    "    weight_decay=hyperparameters[\"adam_weight_decay\"],\n",
    ")\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll initialise an activation resampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_resampler = ActivationResampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a dataset of tokenized prompts, to be used in generating activations (which are in turn\n",
    "used to train the SAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alan/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer: PreTrainedTokenizerBase = src_model.tokenizer  # type: ignore\n",
    "source_data = GenericTextDataset(tokenizer=tokenizer, dataset_path=\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you initialise [wandb](https://wandb.ai/site), the pipeline will automatically log all metrics to\n",
    "wandb. However, we should pass in a dictionary with all of our hyperaparameters so they're on \n",
    "wandb. \n",
    "\n",
    "We strongly encourage users to make use of wandb in order to understand the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ouksaz1w) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2282ad90a14ccfad832f9ec07c2368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>LearnedActivationsL1Loss</td><td>▃▅▆█▃▇▇██▅▅▆▄▂▃▂▂▃▃▃▄▂▁▃▄▄</td></tr><tr><td>LossReducer</td><td>▇▆▇▇▇█▄▇▇▆▆▅▁▄▇▃▅▄▅▅▄▃▄▅▂▁</td></tr><tr><td>MSEReconstructionLoss</td><td>▇▆▇▇▇█▄▇▇▆▆▅▁▄▇▄▅▄▅▅▄▃▄▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>LearnedActivationsL1Loss</td><td>0.00015</td></tr><tr><td>LossReducer</td><td>0.01652</td></tr><tr><td>MSEReconstructionLoss</td><td>0.01637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-valley-60</strong> at: <a href='https://wandb.ai/alan-cooney/sparse-autoencoder/runs/ouksaz1w' target=\"_blank\">https://wandb.ai/alan-cooney/sparse-autoencoder/runs/ouksaz1w</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.cache/wandb/run-20231122_173746-ouksaz1w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 1 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014686844951938838, 'MSEReconstructionLoss': 0.016438545659184456, 'LossReducer': 0.016585413366556168, '_timestamp': 1700693061.415051})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 2 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014744600048288703, 'MSEReconstructionLoss': 0.016695275902748108, 'LossReducer': 0.01684272103011608, '_timestamp': 1700693061.443393})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 3 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014921178808435798, 'MSEReconstructionLoss': 0.016602052375674248, 'LossReducer': 0.016751263290643692, '_timestamp': 1700693061.563891})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 4 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00015085478662513196, 'MSEReconstructionLoss': 0.01657668501138687, 'LossReducer': 0.016727540642023087, '_timestamp': 1700693061.594311})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 5 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014723947970196605, 'MSEReconstructionLoss': 0.016592148691415787, 'LossReducer': 0.016739388927817345, '_timestamp': 1700693061.623855})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 6 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014531883061863482, 'MSEReconstructionLoss': 0.016620565205812454, 'LossReducer': 0.016765883192420006, '_timestamp': 1700693061.652858})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 7 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001476186007494107, 'MSEReconstructionLoss': 0.01663367822766304, 'LossReducer': 0.016781296581029892, '_timestamp': 1700693061.6819541})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 8 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001521612866781652, 'MSEReconstructionLoss': 0.01652052439749241, 'LossReducer': 0.016672685742378235, '_timestamp': 1700693061.711468})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 9 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00015173036081250757, 'MSEReconstructionLoss': 0.016634691506624222, 'LossReducer': 0.016786422580480576, '_timestamp': 1700693061.7414348})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 10 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001487066620029509, 'MSEReconstructionLoss': 0.016614001244306564, 'LossReducer': 0.016762707382440567, '_timestamp': 1700693061.7715998})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 11 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001479105558246374, 'MSEReconstructionLoss': 0.0166058037430048, 'LossReducer': 0.01675371453166008, '_timestamp': 1700693061.802288})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 12 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00015176496526692063, 'MSEReconstructionLoss': 0.016570154577493668, 'LossReducer': 0.016721919178962708, '_timestamp': 1700693061.832801})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 13 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001554945920361206, 'MSEReconstructionLoss': 0.016813328489661217, 'LossReducer': 0.016968823969364166, '_timestamp': 1700693061.8463712})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 14 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014833587920293212, 'MSEReconstructionLoss': 0.01652900129556656, 'LossReducer': 0.016677336767315865, '_timestamp': 1700693063.5010078})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 15 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014472106704488397, 'MSEReconstructionLoss': 0.016578136011958122, 'LossReducer': 0.01672285795211792, '_timestamp': 1700693063.530551})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 16 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014511137851513922, 'MSEReconstructionLoss': 0.01649690791964531, 'LossReducer': 0.016642019152641296, '_timestamp': 1700693063.558675})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 17 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014701577310916036, 'MSEReconstructionLoss': 0.01643894426524639, 'LossReducer': 0.016585959121584892, '_timestamp': 1700693063.588004})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 18 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001470866409363225, 'MSEReconstructionLoss': 0.016581732779741287, 'LossReducer': 0.016728820279240608, '_timestamp': 1700693063.617766})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 19 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014587712939828634, 'MSEReconstructionLoss': 0.01654992438852787, 'LossReducer': 0.01669580116868019, '_timestamp': 1700693063.647893})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 20 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014535995433107018, 'MSEReconstructionLoss': 0.01643543690443039, 'LossReducer': 0.016580797731876373, '_timestamp': 1700693063.6767669})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 21 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001429281837772578, 'MSEReconstructionLoss': 0.016399841755628586, 'LossReducer': 0.016542769968509674, '_timestamp': 1700693063.705984})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 22 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014370981079991907, 'MSEReconstructionLoss': 0.016537705436348915, 'LossReducer': 0.01668141596019268, '_timestamp': 1700693063.734394})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 23 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001464097003918141, 'MSEReconstructionLoss': 0.016581516712903976, 'LossReducer': 0.016727926209568977, '_timestamp': 1700693063.762368})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 24 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014633966202381998, 'MSEReconstructionLoss': 0.01649189367890358, 'LossReducer': 0.01663823425769806, '_timestamp': 1700693063.791723})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "(User provided step: 25 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014529538748320192, 'MSEReconstructionLoss': 0.0165274515748024, 'LossReducer': 0.01667274720966816, '_timestamp': 1700693063.820946})."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ouksaz1w). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b6d42831b943f493026cca418c845a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011119846289026706, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.cache/wandb/run-20231122_180621-o8gzpt6q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alan-cooney/sparse-autoencoder/runs/o8gzpt6q' target=\"_blank\">amber-sun-61</a></strong> to <a href='https://wandb.ai/alan-cooney/sparse-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alan-cooney/sparse-autoencoder' target=\"_blank\">https://wandb.ai/alan-cooney/sparse-autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alan-cooney/sparse-autoencoder/runs/o8gzpt6q' target=\"_blank\">https://wandb.ai/alan-cooney/sparse-autoencoder/runs/o8gzpt6q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/alan-cooney/sparse-autoencoder/runs/o8gzpt6q?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2fc868990>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\".cache/\").mkdir(exist_ok=True)\n",
    "wandb.init(\n",
    "    project=\"sparse-autoencoder\",\n",
    "    dir=\".cache\",\n",
    "    config=hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d353a6a480634f449dcaf3fd5d150db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Activations trained on:   0%|          | 0/10000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 1 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014641458983533084, 'MSEReconstructionLoss': 0.016486823558807373, 'LossReducer': 0.01663323864340782, '_timestamp': 1700695156.0421581}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 2 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014898329391144216, 'MSEReconstructionLoss': 0.016573363915085793, 'LossReducer': 0.01672234758734703, '_timestamp': 1700695156.200486}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 3 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014914142957422882, 'MSEReconstructionLoss': 0.016520731151103973, 'LossReducer': 0.016669873148202896, '_timestamp': 1700695156.23089}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 4 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014537939568981528, 'MSEReconstructionLoss': 0.016562525182962418, 'LossReducer': 0.016707904636859894, '_timestamp': 1700695156.261246}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 5 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014508860476780683, 'MSEReconstructionLoss': 0.01662108674645424, 'LossReducer': 0.016766175627708435, '_timestamp': 1700695156.2897081}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 6 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014607964840251952, 'MSEReconstructionLoss': 0.016750384122133255, 'LossReducer': 0.016896463930606842, '_timestamp': 1700695156.318243}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 7 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001475384196965024, 'MSEReconstructionLoss': 0.01656678318977356, 'LossReducer': 0.016714321449398994, '_timestamp': 1700695156.345904}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 8 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001498426718171686, 'MSEReconstructionLoss': 0.01661980338394642, 'LossReducer': 0.016769645735621452, '_timestamp': 1700695156.3735108}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 9 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001464698143536225, 'MSEReconstructionLoss': 0.016570810228586197, 'LossReducer': 0.016717279329895973, '_timestamp': 1700695156.401262}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 10 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001454194716643542, 'MSEReconstructionLoss': 0.0166291706264019, 'LossReducer': 0.01677458919584751, '_timestamp': 1700695156.4286442}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 11 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014557153917849064, 'MSEReconstructionLoss': 0.016576271504163742, 'LossReducer': 0.01672184281051159, '_timestamp': 1700695156.456595}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 12 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014930625911802053, 'MSEReconstructionLoss': 0.01657012850046158, 'LossReducer': 0.016719434410333633, '_timestamp': 1700695156.484735}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 13 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001493014133302495, 'MSEReconstructionLoss': 0.016870327293872833, 'LossReducer': 0.01701962947845459, '_timestamp': 1700695156.498451}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 14 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014232740795705467, 'MSEReconstructionLoss': 0.016417846083641052, 'LossReducer': 0.01656017266213894, '_timestamp': 1700695158.1438148}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 15 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014400642248801887, 'MSEReconstructionLoss': 0.016499945893883705, 'LossReducer': 0.016643952578306198, '_timestamp': 1700695158.173125}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 16 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014547616592608392, 'MSEReconstructionLoss': 0.016505246981978416, 'LossReducer': 0.016650723293423653, '_timestamp': 1700695158.201431}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 17 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014533582725562155, 'MSEReconstructionLoss': 0.016468103975057602, 'LossReducer': 0.016613440588116646, '_timestamp': 1700695158.2305999}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 18 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014343767543323338, 'MSEReconstructionLoss': 0.016569186002016068, 'LossReducer': 0.016712624579668045, '_timestamp': 1700695158.2585359}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 19 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.0001433975121472031, 'MSEReconstructionLoss': 0.016582466661930084, 'LossReducer': 0.01672586426138878, '_timestamp': 1700695158.28564}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 20 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014466873835772276, 'MSEReconstructionLoss': 0.016465475782752037, 'LossReducer': 0.016610143706202507, '_timestamp': 1700695158.3129852}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 21 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014112386270426214, 'MSEReconstructionLoss': 0.016517462208867073, 'LossReducer': 0.016658585518598557, '_timestamp': 1700695158.3401952}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 22 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014334713341668248, 'MSEReconstructionLoss': 0.01653299480676651, 'LossReducer': 0.016676342114806175, '_timestamp': 1700695158.368292}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 23 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014554911467712373, 'MSEReconstructionLoss': 0.016548670828342438, 'LossReducer': 0.016694219782948494, '_timestamp': 1700695158.395565}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 24 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014428679423872381, 'MSEReconstructionLoss': 0.016586409881711006, 'LossReducer': 0.016730695962905884, '_timestamp': 1700695158.4238799}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 25 is less than current step: 26. Dropping entry: {'LearnedActivationsL1Loss': 0.00014141391147859395, 'MSEReconstructionLoss': 0.016459442675113678, 'LossReducer': 0.01660085655748844, '_timestamp': 1700695158.451683}).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [846, 256] cannot be broadcast to indexing result of shape [1024, 846]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     cache_name\u001b[39m=\u001b[39msrc_model_activation_hook_point,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     layer\u001b[39m=\u001b[39msrc_model_activation_layer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     checkpoint_directory\u001b[39m=\u001b[39mPath(\u001b[39m\"\u001b[39m\u001b[39m../../.checkpoints\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mrun_pipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     train_batch_size\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(hyperparameters[\u001b[39m\"\u001b[39;49m\u001b[39mtrain_batch_size\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     max_store_size\u001b[39m=\u001b[39;49m\u001b[39m100_000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Sizes for demo purposes (you probably want to scale these by 10x)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     max_activations\u001b[39m=\u001b[39;49m\u001b[39m10_000_000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     resample_frequency\u001b[39m=\u001b[39;49m\u001b[39m100_000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     checkpoint_frequency\u001b[39m=\u001b[39;49m\u001b[39m100_000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/demo.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Repos/sparse_autoencoder/sparse_autoencoder/train/abstract_pipeline.py:213\u001b[0m, in \u001b[0;36mAbstractPipeline.run_pipeline\u001b[0;34m(self, train_batch_size, max_store_size, max_activations, resample_frequency, validate_frequency, checkpoint_frequency)\u001b[0m\n\u001b[1;32m    211\u001b[0m progress_bar\u001b[39m.\u001b[39mset_postfix({\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mresample\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m    212\u001b[0m \u001b[39mif\u001b[39;00m last_resampled \u001b[39m>\u001b[39m resample_frequency \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_resampler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresample_neurons(\n\u001b[1;32m    214\u001b[0m         neuron_activity\u001b[39m=\u001b[39;49mneuron_activity,\n\u001b[1;32m    215\u001b[0m         activation_store\u001b[39m=\u001b[39;49mactivation_store,\n\u001b[1;32m    216\u001b[0m         train_batch_size\u001b[39m=\u001b[39;49mtrain_batch_size,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    219\u001b[0m     \u001b[39m# Reset\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_resampled \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Repos/sparse_autoencoder/sparse_autoencoder/train/abstract_pipeline.py:135\u001b[0m, in \u001b[0;36mAbstractPipeline.resample_neurons\u001b[0;34m(self, neuron_activity, activation_store, train_batch_size)\u001b[0m\n\u001b[1;32m    126\u001b[0m parameter_updates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_resampler\u001b[39m.\u001b[39mresample_dead_neurons(\n\u001b[1;32m    127\u001b[0m     neuron_activity\u001b[39m=\u001b[39mneuron_activity,\n\u001b[1;32m    128\u001b[0m     activation_store\u001b[39m=\u001b[39mactivation_store,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     train_batch_size\u001b[39m=\u001b[39mtrain_batch_size,\n\u001b[1;32m    132\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[39m# Update the weights and biases\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautoencoder\u001b[39m.\u001b[39;49mencoder\u001b[39m.\u001b[39;49mupdate_dictionary_vectors(\n\u001b[1;32m    136\u001b[0m     parameter_updates\u001b[39m.\u001b[39;49mdead_neuron_indices,\n\u001b[1;32m    137\u001b[0m     parameter_updates\u001b[39m.\u001b[39;49mdead_encoder_weight_updates,\n\u001b[1;32m    138\u001b[0m )\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoencoder\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mupdate_bias(\n\u001b[1;32m    140\u001b[0m     parameter_updates\u001b[39m.\u001b[39mdead_neuron_indices,\n\u001b[1;32m    141\u001b[0m     parameter_updates\u001b[39m.\u001b[39mdead_encoder_bias_updates,\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoencoder\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mupdate_dictionary_vectors(\n\u001b[1;32m    144\u001b[0m     parameter_updates\u001b[39m.\u001b[39mdead_neuron_indices,\n\u001b[1;32m    145\u001b[0m     parameter_updates\u001b[39m.\u001b[39mdead_decoder_weight_updates,\n\u001b[1;32m    146\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Repos/sparse_autoencoder/sparse_autoencoder/autoencoder/components/abstract_encoder.py:67\u001b[0m, in \u001b[0;36mAbstractEncoder.update_dictionary_vectors\u001b[0;34m(self, dictionary_vector_indices, updated_dictionary_weights)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight[:, dictionary_vector_indices] \u001b[39m=\u001b[39m updated_dictionary_weights\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [846, 256] cannot be broadcast to indexing result of shape [1024, 846]"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    cache_name=src_model_activation_hook_point,\n",
    "    layer=src_model_activation_layer,\n",
    "    source_model=src_model,\n",
    "    autoencoder=autoencoder,\n",
    "    source_dataset=source_data,\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    activation_resampler=activation_resampler,\n",
    "    source_data_batch_size=8,\n",
    "    checkpoint_directory=Path(\"../../.checkpoints\"),\n",
    ")\n",
    "\n",
    "pipeline.run_pipeline(\n",
    "    train_batch_size=int(hyperparameters[\"train_batch_size\"]),\n",
    "    max_store_size=100_000,\n",
    "    # Sizes for demo purposes (you probably want to scale these by 10x)\n",
    "    max_activations=10_000_000,\n",
    "    resample_frequency=100_000,\n",
    "    checkpoint_frequency=100_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fe34fbbf954f53818f400c280378b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>LearnedActivationsL1Loss</td><td>█▇▆▆▆▆▇▆▆▆▇▇▅▅▄▅▄▅▆▅▄▄▄▃▃▃▂▄▆▄▆▃▃▁▂▄▃▄▄▅</td></tr><tr><td>LossReducer</td><td>▆▆▄▆▄▅▁▅▆▆▅▇▆▆▄▄▆▆▇█▆▆▆▂▅▆▅▄▅▇▆▆▇▄▄▅▆▅▅▃</td></tr><tr><td>MSEReconstructionLoss</td><td>▆▆▄▆▄▅▁▅▆▆▅▇▆▆▄▄▆▆▇█▆▆▆▃▅▆▆▄▅▇▆▆▇▄▄▆▆▅▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>LearnedActivationsL1Loss</td><td>0.00015</td></tr><tr><td>LossReducer</td><td>0.01636</td></tr><tr><td>MSEReconstructionLoss</td><td>0.01621</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-silence-59</strong> at: <a href='https://wandb.ai/alan-cooney/sparse-autoencoder/runs/oa3sw525' target=\"_blank\">https://wandb.ai/alan-cooney/sparse-autoencoder/runs/oa3sw525</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.cache/wandb/run-20231122_173322-oa3sw525/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Advice\n",
    "\n",
    "-- Unfinished --\n",
    "\n",
    "- Check recovery loss is low while sparsity is low as well (<20 L1) usually.\n",
    "- Can't be sure features are useful until you dig into them more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "-- Unfinished --"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
