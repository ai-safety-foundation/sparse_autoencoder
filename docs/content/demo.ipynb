{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ai-safety-foundation/sparse_autoencoder/blob/main/docs/content/demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Training Demo\n",
    "\n",
    "This is a quick start demo to get training a SAE right away. All you need to do is choose a few\n",
    "hyperparameters (like the model to train on), and then set it off.\n",
    "By default it replicates Neel Nanda's\n",
    "[comment on the Anthropic dictionary learning\n",
    "paper](https://transformer-circuits.pub/2023/monosemantic-features/index.html#comment-nanda)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab  # noqa: F401 # type: ignore\n",
    "\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "\n",
    "#  Install if in Colab\n",
    "if in_colab:\n",
    "    %pip install sparse_autoencoder transformer_lens transformers wandb\n",
    "\n",
    "# Otherwise enable hot reloading in dev mode\n",
    "if not in_colab:\n",
    "    from IPython import get_ipython  # type: ignore\n",
    "\n",
    "    ip = get_ipython()\n",
    "    if ip is not None and ip.extension_manager is not None and not ip.extension_manager.loaded:\n",
    "        ip.extension_manager.load(\"autoreload\")  # type: ignore\n",
    "        %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sparse_autoencoder import (\n",
    "    sweep,\n",
    "    SweepConfig,\n",
    "    Hyperparameters,\n",
    "    SourceModelHyperparameters,\n",
    "    Parameter,\n",
    "    SourceDataHyperparameters,\n",
    "    Method,\n",
    "    LossHyperparameters,\n",
    "    OptimizerHyperparameters,\n",
    ")\n",
    "import wandb\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"demo.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize any hyperparameters you want below (by default we're sweeping over l1 coefficient and\n",
    "learning rate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = SweepConfig(\n",
    "    parameters=Hyperparameters(\n",
    "        loss=LossHyperparameters(\n",
    "            l1_coefficient=Parameter(values=[1e-3, 1e-4, 1e-5]),\n",
    "        ),\n",
    "        optimizer=OptimizerHyperparameters(\n",
    "            lr=Parameter(values=[1e-3, 1e-4, 1e-5]),\n",
    "        ),\n",
    "        source_model=SourceModelHyperparameters(\n",
    "            name=Parameter(\"gelu-2l\"),\n",
    "            hook_site=Parameter(\"mlp_out\"),\n",
    "            hook_layer=Parameter(0),\n",
    "            hook_dimension=Parameter(512),\n",
    "        ),\n",
    "        source_data=SourceDataHyperparameters(\n",
    "            dataset_path=Parameter(\"NeelNanda/c4-code-tokenized-2b\"),\n",
    "        ),\n",
    "    ),\n",
    "    method=Method.RANDOM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: csjkat4q\n",
      "Sweep URL: https://wandb.ai/alan-cooney/sparse-autoencoder/sweeps/csjkat4q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a6f5i3f8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_resampler: {'dead_neuron_threshold': 0, 'max_resamples': 4, 'n_steps_collate': 100000000, 'resample_dataset_size': 819200, 'resample_interval': 200000000}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tautoencoder: {'expansion_factor': 4}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: {'l1_coefficient': 0.0001}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'adam_beta_1': 0.9, 'adam_beta_2': 0.99, 'adam_weight_decay': 0, 'amsgrad': False, 'fused': False, 'lr': 0.0001}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpipeline: {'checkpoint_frequency': 100000000, 'log_frequency': 100, 'max_activations': 2000000000, 'max_store_size': 3145728, 'source_data_batch_size': 12, 'train_batch_size': 4096, 'validation_frequency': 314572800, 'validation_number_activations': 1024}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 49\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsource_data: {'context_size': 128, 'dataset_path': 'NeelNanda/c4-code-tokenized-2b'}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsource_model: {'dtype': 'float32', 'hook_dimension': 512, 'hook_layer': 0, 'hook_site': 'mlp_out', 'name': 'gelu-2l'}\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malan-cooney\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/alan/Documents/Repos/sparse_autoencoder/docs/content/wandb/run-20231203_164830-a6f5i3f8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alan-cooney/sparse-autoencoder/runs/a6f5i3f8' target=\"_blank\">cosmic-sweep-1</a></strong> to <a href='https://wandb.ai/alan-cooney/sparse-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alan-cooney/sparse-autoencoder/sweeps/csjkat4q' target=\"_blank\">https://wandb.ai/alan-cooney/sparse-autoencoder/sweeps/csjkat4q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alan-cooney/sparse-autoencoder' target=\"_blank\">https://wandb.ai/alan-cooney/sparse-autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alan-cooney/sparse-autoencoder/sweeps/csjkat4q' target=\"_blank\">https://wandb.ai/alan-cooney/sparse-autoencoder/sweeps/csjkat4q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alan-cooney/sparse-autoencoder/runs/a6f5i3f8' target=\"_blank\">https://wandb.ai/alan-cooney/sparse-autoencoder/runs/a6f5i3f8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebd6d99fb20430b848cd395a1fa384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2654993b32c840218c6e7ffffe8c67f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Activations trained on:   0%|          | 0/2000000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alan/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "sweep(sweep_config=sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31186ba1239ad81afeb3c631b4833e71f34259d3b92eebb37a9091b916e08620"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
