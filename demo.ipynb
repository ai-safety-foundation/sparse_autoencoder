{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sparse Autoencoder Training Demo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "# Autoreload\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sparse_autoencoder import TensorActivationStore, SparseAutoencoder, pipeline\n",
                "from sparse_autoencoder.source_data.pile_uncopyrighted import PileUncopyrightedDataset\n",
                "from transformer_lens import HookedTransformer\n",
                "from transformer_lens.utils import get_device\n",
                "from transformers import PreTrainedTokenizerBase\n",
                "import torch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = get_device()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "src_model = HookedTransformer.from_pretrained(\"solu-1l\", dtype=\"float32\")\n",
                "src_d_mlp: int = src_model.cfg.d_mlp  # type: ignore\n",
                "src_d_mlp"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer: PreTrainedTokenizerBase = src_model.tokenizer  # type: ignore\n",
                "source_data = PileUncopyrightedDataset(tokenizer=tokenizer)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Activation Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_items = 1_000_000\n",
                "store = TensorActivationStore(max_items, src_d_mlp, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "autoencoder = SparseAutoencoder(src_d_mlp, src_d_mlp * 8, torch.zeros(src_d_mlp))\n",
                "autoencoder"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you initialise [wandb](https://wandb.ai/site), the pipeline will automatically log all metrics to wandb."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# wandb.init(project=\"sparse-autoencoder\", dir=\".cache/wandb\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pipeline(\n",
                "    src_model=src_model,\n",
                "    src_model_activation_hook_point=\"blocks.0.mlp.hook_post\",\n",
                "    src_model_activation_layer=0,\n",
                "    source_dataset=source_data,\n",
                "    activation_store=store,\n",
                "    num_activations_before_training=max_items,\n",
                "    autoencoder=autoencoder,\n",
                "    device=device,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
