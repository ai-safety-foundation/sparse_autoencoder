{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sparse Autoencoder Training Demo\n",
                "\n",
                "In order to train a sparse autoencoder, we need:\n",
                "1. A model + a layer of that model on which we want to train our autoencoder.\n",
                "2. A dataset which we can use to train generate the activations. \n",
                "3. An autoencoder to be trained. \n",
                "\n",
                "To demonstrate how to train a sparse autoencoder, this notebook shows how to train a sparse\n",
                "autoencoder on the (Tiny-Stories-1M model)[https://huggingface.co/roneneldan/TinyStories-1M].\n",
                "\n",
                "To do so, we make use of the (tiny stories dataset)[https://huggingface.co/datasets/roneneldan/TinyStories].\n",
                "\n",
                "To view other models we can load with hooked transformer, see this (page)[https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html] in the TransformerLens docs.\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Autoreload\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import os\n",
                "\n",
                "import torch\n",
                "from transformer_lens import HookedTransformer\n",
                "from transformer_lens.utils import get_device\n",
                "from transformers import PreTrainedTokenizerBase\n",
                "\n",
                "from sparse_autoencoder import SparseAutoencoder, TensorActivationStore, pipeline\n",
                "from sparse_autoencoder.source_data.text_dataset import GenericTextDataset\n",
                "\n",
                "from sparse_autoencoder.train.sweep_config import SweepParametersRuntime\n",
                "\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "\n",
                "device = get_device()\n",
                "print(f\"Using device: {device}\") # You will need a GPU"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Model and AutoEncoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "src_model_name = \"tiny-stories-1M\"\n",
                "src_model = HookedTransformer.from_pretrained(src_model_name, dtype=\"float32\")\n",
                "src_d_mlp: int = src_model.cfg.d_mlp  # type: ignore\n",
                "\n",
                "src_model_activation_hook_point = \"blocks.0.mlp.hook_post\" # We choose to find features in the output of the first MLP layer.\n",
                "src_model_activation_layer = 0 # This is the layer index of the layer we are hooking into. Possibly can detect by defautl.\n",
                "\n",
                "print(f\"Source model name: {src_model_name}\")\n",
                "print(f\"Source model activation hook point: {src_model_activation_hook_point}\")\n",
                "print(f\"Source model d_mlp: {src_d_mlp}\") # We need the dimension of the activations we are autoencoding. \n",
                "\n",
                "# We can then instantiate the autoencoder\n",
                "expansion_ratio = 8\n",
                "autoencoder = SparseAutoencoder(\n",
                "    n_input_features = src_d_mlp,  # size of the activations we are autoencoding\n",
                "    n_learned_features = src_d_mlp * expansion_ratio, # size of SAE\n",
                "    geometric_median_dataset = torch.zeros(src_d_mlp) # this is used to initialize the tied bias\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Dataset and Activation Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer: PreTrainedTokenizerBase = src_model.tokenizer  # type: ignore\n",
                "\n",
                "# We've implemented a generic wrapper around huggingface datasets.\n",
                "# We'll use the training data for the Tiny Stories model. \n",
                "source_data = GenericTextDataset(tokenizer=tokenizer, dataset_path = \"roneneldan/TinyStories\") \n",
                "\n",
                "# In practice, we load and shuffle data from the dataset. \n",
                "# This is to ensure mixing of the data / prevent overfitting\n",
                "# Optimal/feasible Max Items will depend on your GPU memory.\n",
                "max_items = 1_000_000\n",
                "total_training_tokens = 10_000_000\n",
                "store = TensorActivationStore(max_items, src_d_mlp, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Hyperparameters "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sparse_autoencoder.train.sweep_config import SweepParametersRuntime\n",
                "\n",
                "# Some of the training hyperparameters are passed through in the sweep parameters.\n",
                "# The important thing is to set l1 high enough to get sparsity (eventually),\n",
                "# without compromising the reconstruction loss too much.\n",
                "# Having a large batch size is important too.\n",
                "training_hyperparameters = SweepParametersRuntime(\n",
                "    lr = 0.001, # This is the learning rate\n",
                "    l1_coefficient = 0.001, # This is the coefficient for the L1 regularization\n",
                "    batch_size = 4096, # important that this be quite large.\n",
                "\n",
                "    # Adam Parameters (don't usually need to change these)\n",
                "    adam_beta_1 = 0.9,\n",
                "    adam_beta_2 = 0.999,\n",
                "    adam_epsilon = 1e-8,\n",
                "    adam_weight_decay = 0.0\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "###"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you initialise [wandb](https://wandb.ai/site), the pipeline will automatically log all metrics to\n",
                "wandb. However, we should pass in a dictionary with all of our hyperaparameters so they're on \n",
                "wandb. \n",
                "\n",
                "We strongly encourage users to make use of wandb in order to understand the training process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                " config = {\n",
                "        # Data Params\n",
                "        \"model_name\": src_model_name,\n",
                "        \"hook_point\": src_model_activation_hook_point,\n",
                "        \"src_model_activation_hook_point\": src_model_activation_hook_point,\n",
                "        \"src_model_activation_layer\": src_model_activation_layer,\n",
                "\n",
                "        # SAE params\n",
                "        \"activation_width\": src_d_mlp,\n",
                "        \"expansion_ratio\": expansion_ratio,\n",
                "\n",
                "        # Training params\n",
                "        \"max_items\": max_items,\n",
                "        \"training_tokens\": total_training_tokens,\n",
                "\n",
                "        # other\n",
                "        \"device\": device,\n",
                "    }\n",
                "\n",
                "# add training hyperparameters to config\n",
                "config = config | training_hyperparameters.__dict__\n",
                "config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# skip if you want.\n",
                "import wandb\n",
                "wandb.init(\n",
                "    project=\"sparse-autoencoder\",\n",
                "    dir=\".cache/wandb\",\n",
                "    name=\"demo\",\n",
                "    config=config,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pipeline(\n",
                "    src_model=src_model,\n",
                "    src_model_activation_hook_point=src_model_activation_hook_point,\n",
                "    src_model_activation_layer=src_model_activation_layer,\n",
                "    source_dataset=source_data,\n",
                "    activation_store=store,\n",
                "    num_activations_before_training=max_items,\n",
                "    autoencoder=autoencoder,\n",
                "    device=device,\n",
                "    max_activations=total_training_tokens,\n",
                "    sweep_parameters=training_hyperparameters,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wandb.finish()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Advice\n",
                "\n",
                "-- Unfinished --\n",
                "\n",
                "- Check recovery loss is low while sparsity is low as well (<20 L1) usually.\n",
                "- Can't be sure features are useful until you dig into them more. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analysis\n",
                "\n",
                "-- Unfinished --"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
