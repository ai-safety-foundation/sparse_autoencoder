{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sparse Autoencoder Training Demo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "# Autoreload\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sparse_autoencoder import TensorActivationStore, SparseAutoencoder, pipeline\n",
                "from sparse_autoencoder.source_data.pile_uncopyrighted import PileUncopyrightedDataset\n",
                "from transformer_lens import HookedTransformer\n",
                "from transformer_lens.utils import get_device\n",
                "from transformers import PreTrainedTokenizerBase\n",
                "import torch\n",
                "import wandb"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = get_device()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded pretrained model solu-1l into HookedTransformer\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "2048"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "src_model = HookedTransformer.from_pretrained(\"solu-1l\", dtype=\"float32\")\n",
                "src_d_mlp: int = src_model.cfg.d_mlp  # type: ignore\n",
                "src_d_mlp"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3a7f2473638e4a65bb8bcd5aa7b84762",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "tokenizer: PreTrainedTokenizerBase = src_model.tokenizer  # type: ignore\n",
                "source_data = PileUncopyrightedDataset(tokenizer=tokenizer)\n",
                "src_dataloader = source_data.get_dataloader(batch_size=8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Activation Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_items = 1_000_000\n",
                "store = TensorActivationStore(max_items, src_d_mlp, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "SparseAutoencoder(\n",
                            "  (encoder): Sequential(\n",
                            "    (0): TiedBias(position=TiedBiasPosition.PRE_ENCODER)\n",
                            "    (1): ConstrainedUnitNormLinear(in_features=2048, out_features=16384, bias=True)\n",
                            "    (2): ReLU()\n",
                            "  )\n",
                            "  (decoder): Sequential(\n",
                            "    (0): ConstrainedUnitNormLinear(in_features=16384, out_features=2048, bias=False)\n",
                            "    (1): TiedBias(position=TiedBiasPosition.POST_DECODER)\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "autoencoder = SparseAutoencoder(src_d_mlp, src_d_mlp * 8, torch.zeros(src_d_mlp))\n",
                "autoencoder"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you initialise [wandb](https://wandb.ai/site), the pipeline will automatically log all metrics to wandb."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "# wandb.init(project=\"sparse-autoencoder\", dir=\".cache/wandb\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "425c9664ffcc46bebb1372228fedb044",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generate/Train Cycles: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c8bac4561a6d4b1dbf4af442f7f89179",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generate Activations:   0%|          | 0/2000000 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "pipeline(\n",
                "    src_model=src_model,\n",
                "    src_model_activation_hook_point=\"blocks.0.mlp.hook_post\",\n",
                "    src_model_activation_layer=0,\n",
                "    src_dataloader=src_dataloader,\n",
                "    activation_store=store,\n",
                "    num_activations_before_training=max_items,\n",
                "    autoencoder=autoencoder,\n",
                "    device=device,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
