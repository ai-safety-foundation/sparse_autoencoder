{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sparse Autoencoder Training Demo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Autoreload\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sparse_autoencoder import TensorActivationStore, SparseAutoencoder, pipeline\n",
                "from sparse_autoencoder.source_data.pile_uncopyrighted import PileUncopyrightedDataset\n",
                "from transformer_lens import HookedTransformer\n",
                "from transformer_lens.utils import get_device\n",
                "from transformers import PreTrainedTokenizerBase\n",
                "import torch\n",
                "import os\n",
                "\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = get_device()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded pretrained model solu-1l into HookedTransformer\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "2048"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "src_model = HookedTransformer.from_pretrained(\"solu-1l\", dtype=\"float32\")\n",
                "src_d_mlp: int = src_model.cfg.d_mlp  # type: ignore\n",
                "src_d_mlp"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c607d03e054d4486a468003af2d94ba3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "tokenizer: PreTrainedTokenizerBase = src_model.tokenizer  # type: ignore\n",
                "source_data = PileUncopyrightedDataset(tokenizer=tokenizer)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Activation Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_items = 1_000_000\n",
                "store = TensorActivationStore(max_items, src_d_mlp, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "SparseAutoencoder(\n",
                            "  (encoder): Sequential(\n",
                            "    (TiedBias): TiedBias(position=pre_encoder)\n",
                            "    (Linear): Linear(in_features=2048, out_features=16384, bias=False)\n",
                            "    (ReLU): ReLU()\n",
                            "  )\n",
                            "  (decoder): Sequential(\n",
                            "    (ConstrainedUnitNormLinear): ConstrainedUnitNormLinear(in_features=16384, out_features=2048, bias=False)\n",
                            "    (TiedBias): TiedBias(position=post_decoder)\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "autoencoder = SparseAutoencoder(src_d_mlp, src_d_mlp * 8, torch.zeros(src_d_mlp))\n",
                "autoencoder"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you initialise [wandb](https://wandb.ai/site), the pipeline will automatically log all metrics to wandb."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import wandb\n",
                "# wandb.init(project=\"sparse-autoencoder\", dir=\".cache/wandb\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e759e7b7041d45a484d3054b48dd5e92",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Total activations trained on:   0%|          | 0/100000000 [00:00<?, ?it/s, Generate/train iterations=0]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2d09c19c041444f18d8e0d6bc4ba2832",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generate Activations:   0%|          | 0/1000000 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9e0ee0b671c048b19392fb719482ccbe",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train Autoencoder:   0%|          | 0/996000 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/alan/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
                        "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "91cd7c569b7f40aab0bf5ba31c50d432",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generate Activations:   0%|          | 0/1000000 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bd37148279324daaa7ef2baea6a2f345",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train Autoencoder:   0%|          | 0/996000 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipeline(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     src_model\u001b[39m=\u001b[39;49msrc_model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     src_model_activation_hook_point\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mblocks.0.mlp.hook_post\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     src_model_activation_layer\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     source_dataset\u001b[39m=\u001b[39;49msource_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     activation_store\u001b[39m=\u001b[39;49mstore,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     num_activations_before_training\u001b[39m=\u001b[39;49mmax_items,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     autoencoder\u001b[39m=\u001b[39;49mautoencoder,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     max_activations\u001b[39m=\u001b[39;49m\u001b[39m100_000_000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alan/Documents/Repos/sparse_autoencoder/demo.ipynb#X64sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
                        "File \u001b[0;32m~/Documents/Repos/sparse_autoencoder/sparse_autoencoder/train/pipeline.py:144\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(src_model, src_model_activation_hook_point, src_model_activation_layer, source_dataset, activation_store, num_activations_before_training, autoencoder, source_dataset_batch_size, sweep_parameters, device, max_activations)\u001b[0m\n\u001b[1;32m    141\u001b[0m activation_store\u001b[39m.\u001b[39mshuffle()\n\u001b[1;32m    143\u001b[0m \u001b[39m# Train the autoencoder\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m train_steps \u001b[39m=\u001b[39m train_autoencoder(\n\u001b[1;32m    145\u001b[0m     activation_store\u001b[39m=\u001b[39;49mactivation_store,\n\u001b[1;32m    146\u001b[0m     autoencoder\u001b[39m=\u001b[39;49mautoencoder,\n\u001b[1;32m    147\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    148\u001b[0m     sweep_parameters\u001b[39m=\u001b[39;49msweep_parameters,\n\u001b[1;32m    149\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    150\u001b[0m     previous_steps\u001b[39m=\u001b[39;49mtotal_steps,\n\u001b[1;32m    151\u001b[0m )\n\u001b[1;32m    152\u001b[0m total_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_steps\n\u001b[1;32m    154\u001b[0m total_activations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(activation_store)\n",
                        "File \u001b[0;32m~/Documents/Repos/sparse_autoencoder/sparse_autoencoder/train/train_autoencoder.py:92\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(activation_store, autoencoder, optimizer, sweep_parameters, previous_steps, log_interval, device)\u001b[0m\n\u001b[1;32m     89\u001b[0m learned_activations_fired_count\u001b[39m.\u001b[39madd_(fired\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     91\u001b[0m \u001b[39m# Backwards pass\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m total_loss\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     94\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     96\u001b[0m \u001b[39m# Log\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
                        "File \u001b[0;32m~/Documents/Repos/sparse_autoencoder/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "pipeline(\n",
                "    src_model=src_model,\n",
                "    src_model_activation_hook_point=\"blocks.0.mlp.hook_post\",\n",
                "    src_model_activation_layer=0,\n",
                "    source_dataset=source_data,\n",
                "    activation_store=store,\n",
                "    num_activations_before_training=max_items,\n",
                "    autoencoder=autoencoder,\n",
                "    device=device,\n",
                "    max_activations=100_000_000,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
