
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Sparse Autoencoder for Mechanistic Interpretability">
      
      
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../utils/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.6">
    
    
      
        <title>activation_resampler - Sparse Autoencoder</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../css/material_extra.css">
    
      <link rel="stylesheet" href="../../../css/custom_formatting.css">
    
      <link rel="stylesheet" href="../../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="amber">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#activation-resampler" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Sparse Autoencoder" class="md-header__button md-logo" aria-label="Sparse Autoencoder" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sparse Autoencoder
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              activation_resampler
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="amber"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="amber"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ai-safety-foundation/sparse_autoencoder" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    ai-safety-foundation/sparse_autoencoder
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Sparse Autoencoder" class="md-nav__button md-logo" aria-label="Sparse Autoencoder" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Sparse Autoencoder
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ai-safety-foundation/sparse_autoencoder" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    ai-safety-foundation/sparse_autoencoder
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../demo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Demo
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pre-process-datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Source dataset pre-processing
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    activation_resampler
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            activation_resampler
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    activation_resampler
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    activation_resampler
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler" class="md-nav__link">
    <span class="md-ellipsis">
      activation_resampler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler" class="md-nav__link">
    <span class="md-ellipsis">
      ActivationResampler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ActivationResampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.assign_sampling_probabilities" class="md-nav__link">
    <span class="md-ellipsis">
      assign_sampling_probabilities
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.compute" class="md-nav__link">
    <span class="md-ellipsis">
      compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.renormalize_and_scale" class="md-nav__link">
    <span class="md-ellipsis">
      renormalize_and_scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.sample_input" class="md-nav__link">
    <span class="md-ellipsis">
      sample_input
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.update" class="md-nav__link">
    <span class="md-ellipsis">
      update
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults" class="md-nav__link">
    <span class="md-ellipsis">
      ParameterUpdateResults
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ParameterUpdateResults">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_decoder_weight_updates" class="md-nav__link">
    <span class="md-ellipsis">
      dead_decoder_weight_updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_encoder_bias_updates" class="md-nav__link">
    <span class="md-ellipsis">
      dead_encoder_bias_updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_encoder_weight_updates" class="md-nav__link">
    <span class="md-ellipsis">
      dead_encoder_weight_updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_neuron_indices" class="md-nav__link">
    <span class="md-ellipsis">
      dead_neuron_indices
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../utils/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    utils
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_1_2" id="__nav_4_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_2">
            <span class="md-nav__icon md-icon"></span>
            utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/component_slice_tensor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    component_slice_tensor
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../activation_store/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    activation_store
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            activation_store
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../activation_store/base_store/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base_store
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../activation_store/tensor_store/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_store
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../autoencoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    autoencoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            autoencoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../autoencoder/components/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    components
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_3_1" id="__nav_4_3_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3_1">
            <span class="md-nav__icon md-icon"></span>
            components
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../autoencoder/components/linear_encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear_encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../autoencoder/components/tied_bias/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tied_bias
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../autoencoder/components/unit_norm_decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    unit_norm_decoder
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../autoencoder/lightning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lightning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../autoencoder/model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../autoencoder/types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    types
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../metrics/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    metrics
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            metrics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../metrics/loss/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    loss
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_4_1" id="__nav_4_4_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_1">
            <span class="md-nav__icon md-icon"></span>
            loss
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/loss/l1_absolute_loss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    l1_absolute_loss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/loss/l2_reconstruction_loss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    l2_reconstruction_loss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/loss/sae_loss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sae_loss
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../metrics/train/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    train
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_4_2" id="__nav_4_4_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_2">
            <span class="md-nav__icon md-icon"></span>
            train
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/train/capacity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    capacity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/train/feature_density/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feature_density
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/train/l0_norm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    l0_norm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/train/neuron_activity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    neuron_activity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/train/neuron_fired_count/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    neuron_fired_count
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../metrics/validate/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    validate
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_4_3" id="__nav_4_4_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_3">
            <span class="md-nav__icon md-icon"></span>
            validate
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/validate/reconstruction_score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reconstruction_score
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../metrics/wrappers/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    wrappers
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_4_4" id="__nav_4_4_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_4">
            <span class="md-nav__icon md-icon"></span>
            wrappers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../metrics/wrappers/classwise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    classwise
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../optimizer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    optimizer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            optimizer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optimizer/adam_with_reset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    adam_with_reset
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../source_data/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    source_data
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6">
            <span class="md-nav__icon md-icon"></span>
            source_data
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../source_data/abstract_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abstract_dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../source_data/mock_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mock_dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../source_data/pretokenized_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pretokenized_dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../source_data/text_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_dataset
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../source_model/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    source_model
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_7">
            <span class="md-nav__icon md-icon"></span>
            source_model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../source_model/replace_activations_hook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    replace_activations_hook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../source_model/reshape_activations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reshape_activations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../source_model/store_activations_hook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    store_activations_hook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../source_model/zero_ablate_hook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zero_ablate_hook
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensor_types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../train/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    train
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_9" id="__nav_4_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_9">
            <span class="md-nav__icon md-icon"></span>
            train
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../train/join_sweep/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    join_sweep
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../train/pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../train/sweep/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sweep
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../train/sweep_config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sweep_config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_9_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../train/utils/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    utils
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_9_5" id="__nav_4_9_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_9_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_9_5">
            <span class="md-nav__icon md-icon"></span>
            utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../train/utils/get_model_device/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    get_model_device
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../train/utils/round_down/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    round_down
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../train/utils/wandb_sweep_types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wandb_sweep_types
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../training_runs/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    training_runs
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_10" id="__nav_4_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_10">
            <span class="md-nav__icon md-icon"></span>
            training_runs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_runs/gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_11" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../utils/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    utils
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_11" id="__nav_4_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_11">
            <span class="md-nav__icon md-icon"></span>
            utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/data_parallel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/tensor_shape/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_shape
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../contributing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../citation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Citation
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler" class="md-nav__link">
    <span class="md-ellipsis">
      activation_resampler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler" class="md-nav__link">
    <span class="md-ellipsis">
      ActivationResampler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ActivationResampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.assign_sampling_probabilities" class="md-nav__link">
    <span class="md-ellipsis">
      assign_sampling_probabilities
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.compute" class="md-nav__link">
    <span class="md-ellipsis">
      compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.renormalize_and_scale" class="md-nav__link">
    <span class="md-ellipsis">
      renormalize_and_scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.sample_input" class="md-nav__link">
    <span class="md-ellipsis">
      sample_input
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.update" class="md-nav__link">
    <span class="md-ellipsis">
      update
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults" class="md-nav__link">
    <span class="md-ellipsis">
      ParameterUpdateResults
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ParameterUpdateResults">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_decoder_weight_updates" class="md-nav__link">
    <span class="md-ellipsis">
      dead_decoder_weight_updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_encoder_bias_updates" class="md-nav__link">
    <span class="md-ellipsis">
      dead_encoder_bias_updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_encoder_weight_updates" class="md-nav__link">
    <span class="md-ellipsis">
      dead_encoder_weight_updates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_neuron_indices" class="md-nav__link">
    <span class="md-ellipsis">
      dead_neuron_indices
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="activation-resampler">Activation resampler<a class="headerlink" href="#activation-resampler" title="Permanent link"></a></h1>


<div class="doc doc-object doc-module">



<a id="sparse_autoencoder.activation_resampler.activation_resampler"></a>
  <div class="doc doc-contents first">
  
      <p>Activation resampler.</p>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>          <code>ActivationResampler</code>


<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler" class="headerlink" title="Permanent link"></a></h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="torchmetrics.Metric">Metric</span></code></p>

  
      <p>Activation resampler.</p>
<p>Collates the number of times each neuron fires over a set number of learned activation vectors,
and then provides the parameters necessary to reset any dead neurons.</p>

<details class="motivation" open>
  <summary>Motivation</summary>
  <p>Over the course of training, a subset of autoencoder neurons will have zero activity across
a large number of datapoints. The authors of <em>Towards Monosemanticity: Decomposing Language
Models With Dictionary Learning</em> found that resampling these dead neurons during training
improves the number of likely-interpretable features (i.e., those in the high density
cluster) and reduces total loss. This resampling may be compatible with the Lottery Ticket
Hypothesis and increase the number of chances the network has to find promising feature
directions.</p>
<p>An interesting nuance around dead neurons involves the ultralow density cluster. They found
that if we increase the number of training steps then networks will kill off more of these
ultralow density neurons. This reinforces the use of the high density cluster as a useful
metric because there can exist neurons that are de facto dead but will not appear to be when
looking at the number of dead neurons alone.</p>
<p>This approach is designed to seed new features to fit inputs where the current autoencoder
performs worst. Resetting the encoder norm and bias are crucial to ensuring this resampled
neuron will only fire weakly for inputs similar to the one used for its reinitialization.
This was done to minimize interference with the rest of the network.</p>
</details>
<details class="warning" open>
  <summary>Warning</summary>
  <p>The optimizer should be reset after applying this function, as the Adam state will be
incorrect for the modified weights and biases.</p>
</details>
<details class="warning" open>
  <summary>Warning</summary>
  <p>This approach is also known to create sudden loss spikes, and resampling too frequently
causes training to diverge.</p>
</details>
            <details class="quote">
              <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ActivationResampler</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Activation resampler.</span>

<span class="sd">    Collates the number of times each neuron fires over a set number of learned activation vectors,</span>
<span class="sd">    and then provides the parameters necessary to reset any dead neurons.</span>

<span class="sd">    Motivation:</span>
<span class="sd">        Over the course of training, a subset of autoencoder neurons will have zero activity across</span>
<span class="sd">        a large number of datapoints. The authors of *Towards Monosemanticity: Decomposing Language</span>
<span class="sd">        Models With Dictionary Learning* found that resampling these dead neurons during training</span>
<span class="sd">        improves the number of likely-interpretable features (i.e., those in the high density</span>
<span class="sd">        cluster) and reduces total loss. This resampling may be compatible with the Lottery Ticket</span>
<span class="sd">        Hypothesis and increase the number of chances the network has to find promising feature</span>
<span class="sd">        directions.</span>

<span class="sd">        An interesting nuance around dead neurons involves the ultralow density cluster. They found</span>
<span class="sd">        that if we increase the number of training steps then networks will kill off more of these</span>
<span class="sd">        ultralow density neurons. This reinforces the use of the high density cluster as a useful</span>
<span class="sd">        metric because there can exist neurons that are de facto dead but will not appear to be when</span>
<span class="sd">        looking at the number of dead neurons alone.</span>

<span class="sd">        This approach is designed to seed new features to fit inputs where the current autoencoder</span>
<span class="sd">        performs worst. Resetting the encoder norm and bias are crucial to ensuring this resampled</span>
<span class="sd">        neuron will only fire weakly for inputs similar to the one used for its reinitialization.</span>
<span class="sd">        This was done to minimize interference with the rest of the network.</span>

<span class="sd">    Warning:</span>
<span class="sd">        The optimizer should be reset after applying this function, as the Adam state will be</span>
<span class="sd">        incorrect for the modified weights and biases.</span>

<span class="sd">    Warning:</span>
<span class="sd">        This approach is also known to create sudden loss spikes, and resampling too frequently</span>
<span class="sd">        causes training to diverge.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Collated data from the train loop</span>
    <span class="n">_neuron_fired_count</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)]</span>
    <span class="n">_loss</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">ITEMS</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)]]</span> <span class="o">|</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">ITEMS</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">_input_activations</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span>
        <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">ITEMS</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]</span>
    <span class="p">]</span> <span class="o">|</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">ITEMS</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]</span>

    <span class="c1"># Tracking</span>
    <span class="n">_n_activations_seen_process</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">_n_times_resampled</span><span class="p">:</span> <span class="nb">int</span>

    <span class="c1"># Settings</span>
    <span class="n">_n_components</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">_threshold_is_dead_portion_fires</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">_max_n_resamples</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">resample_interval</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">resample_interval_process</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">start_collecting_neuron_activity_process</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">start_collecting_loss_process</span><span class="p">:</span> <span class="nb">int</span>

    <span class="nd">@validate_call</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_learned_features</span><span class="p">:</span> <span class="n">PositiveInt</span><span class="p">,</span>
        <span class="n">n_components</span><span class="p">:</span> <span class="n">NonNegativeInt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">resample_interval</span><span class="p">:</span> <span class="n">PositiveInt</span> <span class="o">=</span> <span class="mi">200_000_000</span><span class="p">,</span>
        <span class="n">max_n_resamples</span><span class="p">:</span> <span class="n">NonNegativeInt</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">n_activations_activity_collate</span><span class="p">:</span> <span class="n">PositiveInt</span> <span class="o">=</span> <span class="mi">100_000_000</span><span class="p">,</span>
        <span class="n">resample_dataset_size</span><span class="p">:</span> <span class="n">PositiveInt</span> <span class="o">=</span> <span class="mi">819_200</span><span class="p">,</span>
        <span class="n">threshold_is_dead_portion_fires</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Field</span><span class="p">(</span><span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ge</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">le</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Initialize the activation resampler.</span>

<span class="sd">        Defaults to values used in the Anthropic Towards Monosemanticity paper.</span>

<span class="sd">        Args:</span>
<span class="sd">            n_learned_features: Number of learned features</span>
<span class="sd">            n_components: Number of components that the SAE is being trained on.</span>
<span class="sd">            resample_interval: Interval in number of autoencoder input activation vectors trained</span>
<span class="sd">                on, before resampling.</span>
<span class="sd">            max_n_resamples: Maximum number of resamples to perform throughout the entire pipeline.</span>
<span class="sd">                Set to inf if you want to have no limit.</span>
<span class="sd">            n_activations_activity_collate: Number of autoencoder learned activation vectors to</span>
<span class="sd">                collate before resampling (the activation resampler will start collecting on vector</span>
<span class="sd">                $\text{resample_interval} - \text{n_steps_collate}$).</span>
<span class="sd">            resample_dataset_size: Number of autoencoder input activations to use for calculating</span>
<span class="sd">                the loss, as part of the resampling process to create the reset neuron weights.</span>
<span class="sd">            threshold_is_dead_portion_fires: Threshold for determining if a neuron is dead (has</span>
<span class="sd">                &quot;fired&quot; in less than this portion of the collated sample).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If any of the arguments are invalid (e.g. negative integers).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">sync_on_compute</span><span class="o">=</span><span class="kc">False</span>  <span class="c1"># Manually sync instead in compute, where needed</span>
        <span class="p">)</span>

        <span class="c1"># Error handling</span>
        <span class="k">if</span> <span class="n">n_activations_activity_collate</span> <span class="o">&gt;</span> <span class="n">resample_interval</span><span class="p">:</span>
            <span class="n">error_message</span> <span class="o">=</span> <span class="s2">&quot;Must collate less activation activity than the resample interval.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_message</span><span class="p">)</span>

        <span class="c1"># Number of processes</span>
        <span class="n">world_size</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">get_world_size</span><span class="p">(</span><span class="n">group</span><span class="o">.</span><span class="n">WORLD</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">distributed</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span>
            <span class="k">else</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">process_resample_dataset_size</span> <span class="o">=</span> <span class="n">resample_dataset_size</span> <span class="o">//</span> <span class="n">world_size</span>

        <span class="c1"># State setup (note half precision is used as it&#39;s sufficient for resampling purposes)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_state</span><span class="p">(</span>
            <span class="s2">&quot;_neuron_fired_count&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_learned_features</span><span class="p">)),</span>
            <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_state</span><span class="p">(</span><span class="s2">&quot;_loss&quot;</span><span class="p">,</span> <span class="p">[],</span> <span class="s2">&quot;cat&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_state</span><span class="p">(</span><span class="s2">&quot;_input_activations&quot;</span><span class="p">,</span> <span class="p">[],</span> <span class="s2">&quot;cat&quot;</span><span class="p">)</span>

        <span class="c1"># Tracking</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_times_resampled</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Settings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_threshold_is_dead_portion_fires</span> <span class="o">=</span> <span class="n">threshold_is_dead_portion_fires</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_n_resamples</span> <span class="o">=</span> <span class="n">max_n_resamples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval</span> <span class="o">=</span> <span class="n">resample_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval_process</span> <span class="o">=</span> <span class="n">resample_interval</span> <span class="o">//</span> <span class="n">world_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_collecting_neuron_activity_process</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval_process</span> <span class="o">-</span> <span class="n">n_activations_activity_collate</span> <span class="o">//</span> <span class="n">world_size</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_collecting_loss_process</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval_process</span> <span class="o">-</span> <span class="n">process_resample_dataset_size</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
        <span class="p">],</span>
        <span class="n">learned_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)</span>
        <span class="p">],</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)],</span>
        <span class="n">encoder_weight_reference</span><span class="p">:</span> <span class="n">Parameter</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the collated data from forward passes.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_activations: Input activations to the SAE.</span>
<span class="sd">            learned_activations: Learned activations from the SAE.</span>
<span class="sd">            loss: Loss per input activation.</span>
<span class="sd">            encoder_weight_reference: Reference to the SAE encoder weight tensor.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If the loss or input activations are not lists (e.g. from unsync having not</span>
<span class="sd">                been called).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_collecting_neuron_activity_process</span><span class="p">:</span>
            <span class="n">neuron_has_fired</span><span class="p">:</span> <span class="n">Bool</span><span class="p">[</span>
                <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">learned_activations</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span> <span class="o">+=</span> <span class="n">neuron_has_fired</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_collecting_loss_process</span><span class="p">:</span>
            <span class="c1"># Typecast</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_activations</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span>

            <span class="c1"># Append</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_activations</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">learned_activations</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_encoder_weight</span> <span class="o">=</span> <span class="n">encoder_weight_reference</span>

    <span class="k">def</span> <span class="nf">_get_dead_neuron_indices</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Int</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE_IDX</span><span class="p">)]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Identify the indices of neurons that are dead.</span>

<span class="sd">        Identifies any neurons that have fired less than the threshold portion of the collated</span>
<span class="sd">        sample size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of dead neuron indices for each component.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If no neuron activity has been collated yet.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check we have already collated some neuron activity</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">error_message</span> <span class="o">=</span> <span class="s2">&quot;Cannot get dead neuron indices without neuron activity.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_message</span><span class="p">)</span>

        <span class="c1"># Find any neurons that fire less than the threshold portion of times</span>
        <span class="n">threshold_is_dead_n_fires</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_threshold_is_dead_portion_fires</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span><span class="p">[</span><span class="n">component_idx</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">threshold_is_dead_n_fires</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">component_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_components</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">assign_sampling_probabilities</span><span class="p">(</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Assign the sampling probabilities for each input activations vector.</span>

<span class="sd">        Assign each input vector a probability of being picked that is proportional to the square of</span>
<span class="sd">        the autoencoder&#39;s loss on that input.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; loss = torch.tensor([1.0, 2.0, 3.0])</span>
<span class="sd">            &gt;&gt;&gt; ActivationResampler.assign_sampling_probabilities(loss).round(decimals=2)</span>
<span class="sd">            tensor([0.0700, 0.2900, 0.6400])</span>

<span class="sd">            &gt;&gt;&gt; loss = torch.tensor([[1.0, 2], [2, 4], [3, 6]])</span>
<span class="sd">            &gt;&gt;&gt; ActivationResampler.assign_sampling_probabilities(loss).round(decimals=2)</span>
<span class="sd">            tensor([[0.0700, 0.0700],</span>
<span class="sd">                    [0.2900, 0.2900],</span>
<span class="sd">                    [0.6400, 0.6400]])</span>

<span class="sd">        Args:</span>
<span class="sd">            loss: Loss per item.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tensor of probabilities for each item.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">square_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">square_loss</span> <span class="o">/</span> <span class="n">square_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sample_input</span><span class="p">(</span>
        <span class="n">probabilities</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)],</span>
        <span class="n">input_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
        <span class="p">],</span>
        <span class="n">n_samples</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample an input vector based on the provided probabilities.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; probabilities = torch.tensor([[0.1], [0.2], [0.7]])</span>
<span class="sd">            &gt;&gt;&gt; input_activations = torch.tensor([[[1.0, 2.0]], [[3.0, 4.0]], [[5.0, 6.0]]])</span>
<span class="sd">            &gt;&gt;&gt; _seed = torch.manual_seed(0)  # For reproducibility in example</span>
<span class="sd">            &gt;&gt;&gt; sampled_input = ActivationResampler.sample_input(</span>
<span class="sd">            ...     probabilities, input_activations, [2]</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; sampled_input[0].tolist()</span>
<span class="sd">            [[5.0, 6.0], [3.0, 4.0]]</span>

<span class="sd">        Args:</span>
<span class="sd">            probabilities: Probabilities for each input.</span>
<span class="sd">            input_activations: Input activation vectors.</span>
<span class="sd">            n_samples: Number of samples to take (number of dead neurons).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Sampled input activation vector.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the number of samples is greater than the number of input activations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sampled_inputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span>
            <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">component_idx</span><span class="p">,</span> <span class="n">component_n_samples</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="n">component_probabilities</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_component_slice_tensor</span><span class="p">(</span>
                <span class="n">input_tensor</span><span class="o">=</span><span class="n">probabilities</span><span class="p">,</span>
                <span class="n">n_dim_with_component</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">component_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">component_idx</span><span class="o">=</span><span class="n">component_idx</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">component_input_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
                <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">get_component_slice_tensor</span><span class="p">(</span>
                <span class="n">input_tensor</span><span class="o">=</span><span class="n">input_activations</span><span class="p">,</span>
                <span class="n">n_dim_with_component</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">component_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">component_idx</span><span class="o">=</span><span class="n">component_idx</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">component_n_samples</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">component_input_activations</span><span class="p">):</span>
                <span class="n">exception_message</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Cannot sample </span><span class="si">{</span><span class="n">component_n_samples</span><span class="si">}</span><span class="s2"> inputs from &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">component_input_activations</span><span class="p">)</span><span class="si">}</span><span class="s2"> input activations.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">exception_message</span><span class="p">)</span>

            <span class="c1"># Handle the 0 dead neurons case</span>
            <span class="k">if</span> <span class="n">component_n_samples</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sampled_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
                        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">component_input_activations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">component_input_activations</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">component_input_activations</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># Handle the 1+ dead neuron case</span>
            <span class="n">component_sample_indices</span><span class="p">:</span> <span class="n">Int</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE_IDX</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
                <span class="n">component_probabilities</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">component_n_samples</span>
            <span class="p">)</span>
            <span class="n">sampled_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">component_input_activations</span><span class="p">[</span><span class="n">component_sample_indices</span><span class="p">,</span> <span class="p">:])</span>

        <span class="k">return</span> <span class="n">sampled_inputs</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">renormalize_and_scale</span><span class="p">(</span>
        <span class="n">sampled_input</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)],</span>
        <span class="n">neuron_activity</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)],</span>
        <span class="n">encoder_weight</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Renormalize and scale the resampled dictionary vectors.</span>

<span class="sd">        Renormalize the input vector to equal the average norm of the encoder weights for alive</span>
<span class="sd">        neurons times 0.2.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; from torch.nn import Parameter</span>
<span class="sd">            &gt;&gt;&gt; _seed = torch.manual_seed(0)  # For reproducibility in example</span>
<span class="sd">            &gt;&gt;&gt; sampled_input = torch.tensor([[3.0, 4.0]])</span>
<span class="sd">            &gt;&gt;&gt; neuron_activity = torch.tensor([3.0, 0, 5, 0, 1, 3])</span>
<span class="sd">            &gt;&gt;&gt; encoder_weight = Parameter(torch.ones((6, 2)))</span>
<span class="sd">            &gt;&gt;&gt; rescaled_input = ActivationResampler.renormalize_and_scale(</span>
<span class="sd">            ...     sampled_input,</span>
<span class="sd">            ...     neuron_activity,</span>
<span class="sd">            ...     encoder_weight</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; rescaled_input.round(decimals=1)</span>
<span class="sd">            tensor([[0.2000, 0.2000]])</span>

<span class="sd">        Args:</span>
<span class="sd">            sampled_input: Tensor of the sampled input activation.</span>
<span class="sd">            neuron_activity: Tensor representing the number of times each neuron fired.</span>
<span class="sd">            encoder_weight: Tensor of encoder weights.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Rescaled sampled input.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If there are no alive neurons.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">alive_neuron_mask</span><span class="p">:</span> <span class="n">Bool</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot; learned_features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">neuron_activity</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="c1"># Check there is at least one alive neuron</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">alive_neuron_mask</span><span class="p">):</span>
            <span class="n">error_message</span> <span class="o">=</span> <span class="s2">&quot;No alive neurons found.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_message</span><span class="p">)</span>

        <span class="c1"># Handle no dead neurons</span>
        <span class="n">n_dead_neurons</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sampled_input</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_dead_neurons</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sampled_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">sampled_input</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sampled_input</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>

        <span class="c1"># Calculate the average norm of the encoder weights for alive neurons.</span>
        <span class="n">detached_encoder_weight</span> <span class="o">=</span> <span class="n">encoder_weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># Don&#39;t track gradients</span>
        <span class="n">alive_encoder_weights</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">ALIVE_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">detached_encoder_weight</span><span class="p">[</span><span class="n">alive_neuron_mask</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">average_alive_norm</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">SINGLE_ITEM</span><span class="p">]</span> <span class="o">=</span> <span class="n">alive_encoder_weights</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Renormalize the input vector to equal the average norm of the encoder weights for alive</span>
        <span class="c1"># neurons times 0.2.</span>
        <span class="n">renormalized_input</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">sampled_input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">renormalized_input</span> <span class="o">*</span> <span class="p">(</span><span class="n">average_alive_norm</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ParameterUpdateResults</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the parameters that need to be updated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of parameter update results (for each component that the SAE is being trained</span>
<span class="sd">            on), if an update is needed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Resample if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval_process</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="c1"># Initialise results</span>
                <span class="n">parameter_update_results</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ParameterUpdateResults</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="c1"># Sync &amp; typecast</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sync</span><span class="p">()</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">dim_zero_cat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">)</span>
                <span class="n">input_activations</span> <span class="o">=</span> <span class="n">dim_zero_cat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_activations</span><span class="p">)</span>

                <span class="n">dead_neuron_indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span>
                    <span class="n">Int</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE_IDX</span><span class="p">)]</span>
                <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dead_neuron_indices</span><span class="p">()</span>

                <span class="c1"># Assign each input vector a probability of being picked that is proportional to the</span>
                <span class="c1"># square of the autoencoder&#39;s loss on that input.</span>
                <span class="n">sample_probabilities</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
                    <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)</span>
                <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">assign_sampling_probabilities</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

                <span class="c1"># For each dead neuron sample an input according to these probabilities.</span>
                <span class="n">sampled_input</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span>
                    <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]</span>
                <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span><span class="p">(</span>
                    <span class="n">sample_probabilities</span><span class="p">,</span>
                    <span class="n">input_activations</span><span class="p">,</span>
                    <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">dead</span><span class="p">)</span> <span class="k">for</span> <span class="n">dead</span> <span class="ow">in</span> <span class="n">dead_neuron_indices</span><span class="p">],</span>
                <span class="p">)</span>

                <span class="k">for</span> <span class="n">component_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_components</span><span class="p">):</span>
                    <span class="c1"># Renormalize each input vector to have unit L2 norm and set this to be the</span>
                    <span class="c1"># dictionary vector for the dead autoencoder neuron.</span>
                    <span class="n">renormalized_input</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
                        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
                    <span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">sampled_input</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

                    <span class="n">dead_decoder_weight_updates</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span>
                        <span class="n">renormalized_input</span><span class="p">,</span> <span class="s2">&quot;dead_neuron input_feature -&gt; input_feature dead_neuron&quot;</span>
                    <span class="p">)</span>

                    <span class="c1"># For the corresponding encoder vector, renormalize the input vector to equal</span>
                    <span class="c1"># the average norm of the encoder weights for alive neurons times 0.2. Set the</span>
                    <span class="c1"># corresponding encoder bias element to zero.</span>
                    <span class="n">encoder_weight</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
                        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
                    <span class="p">]</span> <span class="o">=</span> <span class="n">get_component_slice_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoder_weight</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">component_idx</span><span class="p">)</span>

                    <span class="n">rescaled_sampled_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">renormalize_and_scale</span><span class="p">(</span>
                        <span class="n">sampled_input</span><span class="o">=</span><span class="n">sampled_input</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span>
                        <span class="n">neuron_activity</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span>
                        <span class="n">encoder_weight</span><span class="o">=</span><span class="n">encoder_weight</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="n">dead_encoder_bias_updates</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span>
                        <span class="n">dead_neuron_indices</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">dead_decoder_weight_updates</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">dead_decoder_weight_updates</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="n">parameter_update_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">ParameterUpdateResults</span><span class="p">(</span>
                            <span class="n">dead_neuron_indices</span><span class="o">=</span><span class="n">dead_neuron_indices</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span>
                            <span class="n">dead_encoder_weight_updates</span><span class="o">=</span><span class="n">rescaled_sampled_input</span><span class="p">,</span>
                            <span class="n">dead_encoder_bias_updates</span><span class="o">=</span><span class="n">dead_encoder_bias_updates</span><span class="p">,</span>
                            <span class="n">dead_decoder_weight_updates</span><span class="o">=</span><span class="n">dead_decoder_weight_updates</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

                <span class="c1"># Reset</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">unsync</span><span class="p">(</span><span class="n">should_unsync</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_synced</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

                <span class="k">return</span> <span class="n">parameter_update_results</span>

        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>  <span class="c1"># type: ignore[override]</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
        <span class="p">],</span>
        <span class="n">learned_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)</span>
        <span class="p">],</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)],</span>
        <span class="n">encoder_weight_reference</span><span class="p">:</span> <span class="n">Parameter</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ParameterUpdateResults</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Step the resampler, collating neuron activity and resampling if necessary.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_activations: Input activations to the SAE.</span>
<span class="sd">            learned_activations: Learned activations from the SAE.</span>
<span class="sd">            loss: Loss per input activation.</span>
<span class="sd">            encoder_weight_reference: Reference to the SAE encoder weight tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Parameter update results (for each component that the SAE is being trained on) if</span>
<span class="sd">            resampling is due. Otherwise None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Don&#39;t do anything if we have already completed all resamples</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_times_resampled</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_n_resamples</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">input_activations</span><span class="o">=</span><span class="n">input_activations</span><span class="p">,</span>
            <span class="n">learned_activations</span><span class="o">=</span><span class="n">learned_activations</span><span class="p">,</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">encoder_weight_reference</span><span class="o">=</span><span class="n">encoder_weight_reference</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset the activation resampler.</span>

<span class="sd">        Warning:</span>
<span class="sd">            This is only called when forward/compute has returned parameters to update (i.e.</span>
<span class="sd">            resampling is due).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_activations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_times_resampled</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.__init__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">n_learned_features</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">resample_interval</span><span class="o">=</span><span class="mi">200000000</span><span class="p">,</span> <span class="n">max_n_resamples</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_activations_activity_collate</span><span class="o">=</span><span class="mi">100000000</span><span class="p">,</span> <span class="n">resample_dataset_size</span><span class="o">=</span><span class="mi">819200</span><span class="p">,</span> <span class="n">threshold_is_dead_portion_fires</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span></code>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.__init__" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Initialize the activation resampler.</p>
<p>Defaults to values used in the Anthropic Towards Monosemanticity paper.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>n_learned_features</code></td>
          <td>
                <code><span title="pydantic.PositiveInt">PositiveInt</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Number of learned features</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>n_components</code></td>
          <td>
                <code><span title="pydantic.NonNegativeInt">NonNegativeInt</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Number of components that the SAE is being trained on.</p>
            </div>
          </td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>resample_interval</code></td>
          <td>
                <code><span title="pydantic.PositiveInt">PositiveInt</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Interval in number of autoencoder input activation vectors trained
on, before resampling.</p>
            </div>
          </td>
          <td>
                <code>200000000</code>
          </td>
        </tr>
        <tr>
          <td><code>max_n_resamples</code></td>
          <td>
                <code><span title="pydantic.NonNegativeInt">NonNegativeInt</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Maximum number of resamples to perform throughout the entire pipeline.
Set to inf if you want to have no limit.</p>
            </div>
          </td>
          <td>
                <code>4</code>
          </td>
        </tr>
        <tr>
          <td><code>n_activations_activity_collate</code></td>
          <td>
                <code><span title="pydantic.PositiveInt">PositiveInt</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Number of autoencoder learned activation vectors to
collate before resampling (the activation resampler will start collecting on vector
<span class="arithmatex">\(\text{resample_interval} - \text{n_steps_collate}\)</span>).</p>
            </div>
          </td>
          <td>
                <code>100000000</code>
          </td>
        </tr>
        <tr>
          <td><code>resample_dataset_size</code></td>
          <td>
                <code><span title="pydantic.PositiveInt">PositiveInt</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Number of autoencoder input activations to use for calculating
the loss, as part of the resampling process to create the reset neuron weights.</p>
            </div>
          </td>
          <td>
                <code>819200</code>
          </td>
        </tr>
        <tr>
          <td><code>threshold_is_dead_portion_fires</code></td>
          <td>
                <code><span title="typing.Annotated">Annotated</span>[float, <span title="pydantic.Field">Field</span>(strict=True, ge=0, le=1)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Threshold for determining if a neuron is dead (has
"fired" in less than this portion of the collated sample).</p>
            </div>
          </td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If any of the arguments are invalid (e.g. negative integers).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@validate_call</span>
<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">n_learned_features</span><span class="p">:</span> <span class="n">PositiveInt</span><span class="p">,</span>
    <span class="n">n_components</span><span class="p">:</span> <span class="n">NonNegativeInt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">resample_interval</span><span class="p">:</span> <span class="n">PositiveInt</span> <span class="o">=</span> <span class="mi">200_000_000</span><span class="p">,</span>
    <span class="n">max_n_resamples</span><span class="p">:</span> <span class="n">NonNegativeInt</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">n_activations_activity_collate</span><span class="p">:</span> <span class="n">PositiveInt</span> <span class="o">=</span> <span class="mi">100_000_000</span><span class="p">,</span>
    <span class="n">resample_dataset_size</span><span class="p">:</span> <span class="n">PositiveInt</span> <span class="o">=</span> <span class="mi">819_200</span><span class="p">,</span>
    <span class="n">threshold_is_dead_portion_fires</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Field</span><span class="p">(</span><span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ge</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">le</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Initialize the activation resampler.</span>

<span class="sd">    Defaults to values used in the Anthropic Towards Monosemanticity paper.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_learned_features: Number of learned features</span>
<span class="sd">        n_components: Number of components that the SAE is being trained on.</span>
<span class="sd">        resample_interval: Interval in number of autoencoder input activation vectors trained</span>
<span class="sd">            on, before resampling.</span>
<span class="sd">        max_n_resamples: Maximum number of resamples to perform throughout the entire pipeline.</span>
<span class="sd">            Set to inf if you want to have no limit.</span>
<span class="sd">        n_activations_activity_collate: Number of autoencoder learned activation vectors to</span>
<span class="sd">            collate before resampling (the activation resampler will start collecting on vector</span>
<span class="sd">            $\text{resample_interval} - \text{n_steps_collate}$).</span>
<span class="sd">        resample_dataset_size: Number of autoencoder input activations to use for calculating</span>
<span class="sd">            the loss, as part of the resampling process to create the reset neuron weights.</span>
<span class="sd">        threshold_is_dead_portion_fires: Threshold for determining if a neuron is dead (has</span>
<span class="sd">            &quot;fired&quot; in less than this portion of the collated sample).</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If any of the arguments are invalid (e.g. negative integers).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">sync_on_compute</span><span class="o">=</span><span class="kc">False</span>  <span class="c1"># Manually sync instead in compute, where needed</span>
    <span class="p">)</span>

    <span class="c1"># Error handling</span>
    <span class="k">if</span> <span class="n">n_activations_activity_collate</span> <span class="o">&gt;</span> <span class="n">resample_interval</span><span class="p">:</span>
        <span class="n">error_message</span> <span class="o">=</span> <span class="s2">&quot;Must collate less activation activity than the resample interval.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_message</span><span class="p">)</span>

    <span class="c1"># Number of processes</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">get_world_size</span><span class="p">(</span><span class="n">group</span><span class="o">.</span><span class="n">WORLD</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">distributed</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span>
        <span class="k">else</span> <span class="mi">1</span>
    <span class="p">)</span>
    <span class="n">process_resample_dataset_size</span> <span class="o">=</span> <span class="n">resample_dataset_size</span> <span class="o">//</span> <span class="n">world_size</span>

    <span class="c1"># State setup (note half precision is used as it&#39;s sufficient for resampling purposes)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_state</span><span class="p">(</span>
        <span class="s2">&quot;_neuron_fired_count&quot;</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_components</span><span class="p">,</span> <span class="n">n_learned_features</span><span class="p">)),</span>
        <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_state</span><span class="p">(</span><span class="s2">&quot;_loss&quot;</span><span class="p">,</span> <span class="p">[],</span> <span class="s2">&quot;cat&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_state</span><span class="p">(</span><span class="s2">&quot;_input_activations&quot;</span><span class="p">,</span> <span class="p">[],</span> <span class="s2">&quot;cat&quot;</span><span class="p">)</span>

    <span class="c1"># Tracking</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_n_times_resampled</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Settings</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_n_components</span> <span class="o">=</span> <span class="n">n_components</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_threshold_is_dead_portion_fires</span> <span class="o">=</span> <span class="n">threshold_is_dead_portion_fires</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_max_n_resamples</span> <span class="o">=</span> <span class="n">max_n_resamples</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval</span> <span class="o">=</span> <span class="n">resample_interval</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval_process</span> <span class="o">=</span> <span class="n">resample_interval</span> <span class="o">//</span> <span class="n">world_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">start_collecting_neuron_activity_process</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval_process</span> <span class="o">-</span> <span class="n">n_activations_activity_collate</span> <span class="o">//</span> <span class="n">world_size</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">start_collecting_loss_process</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval_process</span> <span class="o">-</span> <span class="n">process_resample_dataset_size</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.assign_sampling_probabilities" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">assign_sampling_probabilities</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.assign_sampling_probabilities" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Assign the sampling probabilities for each input activations vector.</p>
<p>Assign each input vector a probability of being picked that is proportional to the square of
the autoencoder's loss on that input.</p>



<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ActivationResampler</span><span class="o">.</span><span class="n">assign_sampling_probabilities</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([0.0700, 0.2900, 0.6400])</span>
</code></pre></div>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ActivationResampler</span><span class="o">.</span><span class="n">assign_sampling_probabilities</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([[0.0700, 0.0700],</span>
<span class="go">        [0.2900, 0.2900],</span>
<span class="go">        [0.6400, 0.6400]])</span>
</code></pre></div>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>loss</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Loss per item.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A tensor of probabilities for each item.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">assign_sampling_probabilities</span><span class="p">(</span>
    <span class="n">loss</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Assign the sampling probabilities for each input activations vector.</span>

<span class="sd">    Assign each input vector a probability of being picked that is proportional to the square of</span>
<span class="sd">    the autoencoder&#39;s loss on that input.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; loss = torch.tensor([1.0, 2.0, 3.0])</span>
<span class="sd">        &gt;&gt;&gt; ActivationResampler.assign_sampling_probabilities(loss).round(decimals=2)</span>
<span class="sd">        tensor([0.0700, 0.2900, 0.6400])</span>

<span class="sd">        &gt;&gt;&gt; loss = torch.tensor([[1.0, 2], [2, 4], [3, 6]])</span>
<span class="sd">        &gt;&gt;&gt; ActivationResampler.assign_sampling_probabilities(loss).round(decimals=2)</span>
<span class="sd">        tensor([[0.0700, 0.0700],</span>
<span class="sd">                [0.2900, 0.2900],</span>
<span class="sd">                [0.6400, 0.6400]])</span>

<span class="sd">    Args:</span>
<span class="sd">        loss: Loss per item.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor of probabilities for each item.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">square_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">square_loss</span> <span class="o">/</span> <span class="n">square_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.compute" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">compute</span><span class="p">()</span></code>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.compute" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Compute the parameters that need to be updated.</p>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>list[<a class="autorefs autorefs-internal" title="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults" href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults">ParameterUpdateResults</a>] | None</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A list of parameter update results (for each component that the SAE is being trained</p>
            </div>
          </td>
        </tr>
        <tr>
          <td>
                <code>list[<a class="autorefs autorefs-internal" title="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults" href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults">ParameterUpdateResults</a>] | None</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>on), if an update is needed.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ParameterUpdateResults</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the parameters that need to be updated.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of parameter update results (for each component that the SAE is being trained</span>
<span class="sd">        on), if an update is needed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Resample if needed</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample_interval_process</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Initialise results</span>
            <span class="n">parameter_update_results</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ParameterUpdateResults</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Sync &amp; typecast</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sync</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">dim_zero_cat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">)</span>
            <span class="n">input_activations</span> <span class="o">=</span> <span class="n">dim_zero_cat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_activations</span><span class="p">)</span>

            <span class="n">dead_neuron_indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span>
                <span class="n">Int</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE_IDX</span><span class="p">)]</span>
            <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dead_neuron_indices</span><span class="p">()</span>

            <span class="c1"># Assign each input vector a probability of being picked that is proportional to the</span>
            <span class="c1"># square of the autoencoder&#39;s loss on that input.</span>
            <span class="n">sample_probabilities</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
                <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)</span>
            <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">assign_sampling_probabilities</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1"># For each dead neuron sample an input according to these probabilities.</span>
            <span class="n">sampled_input</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span>
                <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]</span>
            <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span><span class="p">(</span>
                <span class="n">sample_probabilities</span><span class="p">,</span>
                <span class="n">input_activations</span><span class="p">,</span>
                <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">dead</span><span class="p">)</span> <span class="k">for</span> <span class="n">dead</span> <span class="ow">in</span> <span class="n">dead_neuron_indices</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">component_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_components</span><span class="p">):</span>
                <span class="c1"># Renormalize each input vector to have unit L2 norm and set this to be the</span>
                <span class="c1"># dictionary vector for the dead autoencoder neuron.</span>
                <span class="n">renormalized_input</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
                    <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
                <span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">sampled_input</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

                <span class="n">dead_decoder_weight_updates</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span>
                    <span class="n">renormalized_input</span><span class="p">,</span> <span class="s2">&quot;dead_neuron input_feature -&gt; input_feature dead_neuron&quot;</span>
                <span class="p">)</span>

                <span class="c1"># For the corresponding encoder vector, renormalize the input vector to equal</span>
                <span class="c1"># the average norm of the encoder weights for alive neurons times 0.2. Set the</span>
                <span class="c1"># corresponding encoder bias element to zero.</span>
                <span class="n">encoder_weight</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
                    <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
                <span class="p">]</span> <span class="o">=</span> <span class="n">get_component_slice_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoder_weight</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">component_idx</span><span class="p">)</span>

                <span class="n">rescaled_sampled_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">renormalize_and_scale</span><span class="p">(</span>
                    <span class="n">sampled_input</span><span class="o">=</span><span class="n">sampled_input</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span>
                    <span class="n">neuron_activity</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span>
                    <span class="n">encoder_weight</span><span class="o">=</span><span class="n">encoder_weight</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">dead_encoder_bias_updates</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span>
                    <span class="n">dead_neuron_indices</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dead_decoder_weight_updates</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">dead_decoder_weight_updates</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">parameter_update_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">ParameterUpdateResults</span><span class="p">(</span>
                        <span class="n">dead_neuron_indices</span><span class="o">=</span><span class="n">dead_neuron_indices</span><span class="p">[</span><span class="n">component_idx</span><span class="p">],</span>
                        <span class="n">dead_encoder_weight_updates</span><span class="o">=</span><span class="n">rescaled_sampled_input</span><span class="p">,</span>
                        <span class="n">dead_encoder_bias_updates</span><span class="o">=</span><span class="n">dead_encoder_bias_updates</span><span class="p">,</span>
                        <span class="n">dead_decoder_weight_updates</span><span class="o">=</span><span class="n">dead_decoder_weight_updates</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># Reset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unsync</span><span class="p">(</span><span class="n">should_unsync</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_synced</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">parameter_update_results</span>

    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">input_activations</span><span class="p">,</span> <span class="n">learned_activations</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">encoder_weight_reference</span><span class="p">)</span></code>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.forward" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Step the resampler, collating neuron activity and resampling if necessary.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>input_activations</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE">INPUT_OUTPUT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Input activations to the SAE.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>learned_activations</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.LEARNT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.LEARNT_FEATURE">LEARNT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Learned activations from the SAE.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>loss</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Loss per input activation.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>encoder_weight_reference</code></td>
          <td>
                <code><span title="torch.nn.Parameter">Parameter</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Reference to the SAE encoder weight tensor.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>list[<a class="autorefs autorefs-internal" title="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults" href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults">ParameterUpdateResults</a>] | None</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Parameter update results (for each component that the SAE is being trained on) if</p>
            </div>
          </td>
        </tr>
        <tr>
          <td>
                <code>list[<a class="autorefs autorefs-internal" title="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults" href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults">ParameterUpdateResults</a>] | None</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>resampling is due. Otherwise None.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>  <span class="c1"># type: ignore[override]</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">learned_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">loss</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)],</span>
    <span class="n">encoder_weight_reference</span><span class="p">:</span> <span class="n">Parameter</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ParameterUpdateResults</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Step the resampler, collating neuron activity and resampling if necessary.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_activations: Input activations to the SAE.</span>
<span class="sd">        learned_activations: Learned activations from the SAE.</span>
<span class="sd">        loss: Loss per input activation.</span>
<span class="sd">        encoder_weight_reference: Reference to the SAE encoder weight tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Parameter update results (for each component that the SAE is being trained on) if</span>
<span class="sd">        resampling is due. Otherwise None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Don&#39;t do anything if we have already completed all resamples</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_times_resampled</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_n_resamples</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">input_activations</span><span class="o">=</span><span class="n">input_activations</span><span class="p">,</span>
        <span class="n">learned_activations</span><span class="o">=</span><span class="n">learned_activations</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">encoder_weight_reference</span><span class="o">=</span><span class="n">encoder_weight_reference</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.renormalize_and_scale" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">renormalize_and_scale</span><span class="p">(</span><span class="n">sampled_input</span><span class="p">,</span> <span class="n">neuron_activity</span><span class="p">,</span> <span class="n">encoder_weight</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.renormalize_and_scale" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Renormalize and scale the resampled dictionary vectors.</p>
<p>Renormalize the input vector to equal the average norm of the encoder weights for alive
neurons times 0.2.</p>

<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torch.nn import Parameter
_seed = torch.manual_seed(0)  # For reproducibility in example
sampled_input = torch.tensor([[3.0, 4.0]])
neuron_activity = torch.tensor([3.0, 0, 5, 0, 1, 3])
encoder_weight = Parameter(torch.ones((6, 2)))
rescaled_input = ActivationResampler.renormalize_and_scale(
...     sampled_input,
...     neuron_activity,
...     encoder_weight
... )
rescaled_input.round(decimals=1)
tensor([[0.2000, 0.2000]])</p>
</blockquote>
</blockquote>
</blockquote>
</details>


  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>sampled_input</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.DEAD_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.DEAD_FEATURE">DEAD_FEATURE</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE">INPUT_OUTPUT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Tensor of the sampled input activation.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>neuron_activity</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.LEARNT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.LEARNT_FEATURE">LEARNT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Tensor representing the number of times each neuron fired.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>encoder_weight</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.LEARNT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.LEARNT_FEATURE">LEARNT_FEATURE</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE">INPUT_OUTPUT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Tensor of encoder weights.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.DEAD_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.DEAD_FEATURE">DEAD_FEATURE</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE">INPUT_OUTPUT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Rescaled sampled input.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If there are no alive neurons.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">renormalize_and_scale</span><span class="p">(</span>
    <span class="n">sampled_input</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)],</span>
    <span class="n">neuron_activity</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)],</span>
    <span class="n">encoder_weight</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Renormalize and scale the resampled dictionary vectors.</span>

<span class="sd">    Renormalize the input vector to equal the average norm of the encoder weights for alive</span>
<span class="sd">    neurons times 0.2.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; from torch.nn import Parameter</span>
<span class="sd">        &gt;&gt;&gt; _seed = torch.manual_seed(0)  # For reproducibility in example</span>
<span class="sd">        &gt;&gt;&gt; sampled_input = torch.tensor([[3.0, 4.0]])</span>
<span class="sd">        &gt;&gt;&gt; neuron_activity = torch.tensor([3.0, 0, 5, 0, 1, 3])</span>
<span class="sd">        &gt;&gt;&gt; encoder_weight = Parameter(torch.ones((6, 2)))</span>
<span class="sd">        &gt;&gt;&gt; rescaled_input = ActivationResampler.renormalize_and_scale(</span>
<span class="sd">        ...     sampled_input,</span>
<span class="sd">        ...     neuron_activity,</span>
<span class="sd">        ...     encoder_weight</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; rescaled_input.round(decimals=1)</span>
<span class="sd">        tensor([[0.2000, 0.2000]])</span>

<span class="sd">    Args:</span>
<span class="sd">        sampled_input: Tensor of the sampled input activation.</span>
<span class="sd">        neuron_activity: Tensor representing the number of times each neuron fired.</span>
<span class="sd">        encoder_weight: Tensor of encoder weights.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Rescaled sampled input.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If there are no alive neurons.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">alive_neuron_mask</span><span class="p">:</span> <span class="n">Bool</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot; learned_features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">neuron_activity</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="c1"># Check there is at least one alive neuron</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">alive_neuron_mask</span><span class="p">):</span>
        <span class="n">error_message</span> <span class="o">=</span> <span class="s2">&quot;No alive neurons found.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_message</span><span class="p">)</span>

    <span class="c1"># Handle no dead neurons</span>
    <span class="n">n_dead_neurons</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sampled_input</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_dead_neurons</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sampled_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">sampled_input</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sampled_input</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>

    <span class="c1"># Calculate the average norm of the encoder weights for alive neurons.</span>
    <span class="n">detached_encoder_weight</span> <span class="o">=</span> <span class="n">encoder_weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># Don&#39;t track gradients</span>
    <span class="n">alive_encoder_weights</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">ALIVE_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">detached_encoder_weight</span><span class="p">[</span><span class="n">alive_neuron_mask</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">average_alive_norm</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">SINGLE_ITEM</span><span class="p">]</span> <span class="o">=</span> <span class="n">alive_encoder_weights</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
        <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="c1"># Renormalize the input vector to equal the average norm of the encoder weights for alive</span>
    <span class="c1"># neurons times 0.2.</span>
    <span class="n">renormalized_input</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">sampled_input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">renormalized_input</span> <span class="o">*</span> <span class="p">(</span><span class="n">average_alive_norm</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.reset" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">reset</span><span class="p">()</span></code>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.reset" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Reset the activation resampler.</p>

<details class="warning" open>
  <summary>Warning</summary>
  <p>This is only called when forward/compute has returned parameters to update (i.e.
resampling is due).</p>
</details>
          <details class="quote">
            <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reset the activation resampler.</span>

<span class="sd">    Warning:</span>
<span class="sd">        This is only called when forward/compute has returned parameters to update (i.e.</span>
<span class="sd">        resampling is due).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_activations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_n_times_resampled</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.sample_input" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">sample_input</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">input_activations</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.sample_input" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Sample an input vector based on the provided probabilities.</p>

<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>probabilities = torch.tensor([[0.1], [0.2], [0.7]])
input_activations = torch.tensor([[[1.0, 2.0]], [[3.0, 4.0]], [[5.0, 6.0]]])
_seed = torch.manual_seed(0)  # For reproducibility in example
sampled_input = ActivationResampler.sample_input(
...     probabilities, input_activations, [2]
... )
sampled_input[0].tolist()
[[5.0, 6.0], [3.0, 4.0]]</p>
</blockquote>
</blockquote>
</blockquote>
</details>


  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>probabilities</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Probabilities for each input.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>input_activations</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE">INPUT_OUTPUT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Input activation vectors.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>n_samples</code></td>
          <td>
                <code>list[int]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Number of samples to take (number of dead neurons).</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>list[<span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.DEAD_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.DEAD_FEATURE">DEAD_FEATURE</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE">INPUT_OUTPUT_FEATURE</a>)]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Sampled input activation vector.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If the number of samples is greater than the number of input activations.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">sample_input</span><span class="p">(</span>
    <span class="n">probabilities</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)],</span>
    <span class="n">input_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample an input vector based on the provided probabilities.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; probabilities = torch.tensor([[0.1], [0.2], [0.7]])</span>
<span class="sd">        &gt;&gt;&gt; input_activations = torch.tensor([[[1.0, 2.0]], [[3.0, 4.0]], [[5.0, 6.0]]])</span>
<span class="sd">        &gt;&gt;&gt; _seed = torch.manual_seed(0)  # For reproducibility in example</span>
<span class="sd">        &gt;&gt;&gt; sampled_input = ActivationResampler.sample_input(</span>
<span class="sd">        ...     probabilities, input_activations, [2]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; sampled_input[0].tolist()</span>
<span class="sd">        [[5.0, 6.0], [3.0, 4.0]]</span>

<span class="sd">    Args:</span>
<span class="sd">        probabilities: Probabilities for each input.</span>
<span class="sd">        input_activations: Input activation vectors.</span>
<span class="sd">        n_samples: Number of samples to take (number of dead neurons).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Sampled input activation vector.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the number of samples is greater than the number of input activations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sampled_inputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span>
        <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">component_idx</span><span class="p">,</span> <span class="n">component_n_samples</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="n">component_probabilities</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_component_slice_tensor</span><span class="p">(</span>
            <span class="n">input_tensor</span><span class="o">=</span><span class="n">probabilities</span><span class="p">,</span>
            <span class="n">n_dim_with_component</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">component_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">component_idx</span><span class="o">=</span><span class="n">component_idx</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">component_input_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">get_component_slice_tensor</span><span class="p">(</span>
            <span class="n">input_tensor</span><span class="o">=</span><span class="n">input_activations</span><span class="p">,</span>
            <span class="n">n_dim_with_component</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">component_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">component_idx</span><span class="o">=</span><span class="n">component_idx</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">component_n_samples</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">component_input_activations</span><span class="p">):</span>
            <span class="n">exception_message</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot sample </span><span class="si">{</span><span class="n">component_n_samples</span><span class="si">}</span><span class="s2"> inputs from &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">component_input_activations</span><span class="p">)</span><span class="si">}</span><span class="s2"> input activations.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">exception_message</span><span class="p">)</span>

        <span class="c1"># Handle the 0 dead neurons case</span>
        <span class="k">if</span> <span class="n">component_n_samples</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sampled_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
                    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">component_input_activations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">component_input_activations</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">component_input_activations</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># Handle the 1+ dead neuron case</span>
        <span class="n">component_sample_indices</span><span class="p">:</span> <span class="n">Int</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE_IDX</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
            <span class="n">component_probabilities</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">component_n_samples</span>
        <span class="p">)</span>
        <span class="n">sampled_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">component_input_activations</span><span class="p">[</span><span class="n">component_sample_indices</span><span class="p">,</span> <span class="p">:])</span>

    <span class="k">return</span> <span class="n">sampled_inputs</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.update" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>          <code class="highlight language-python"><span class="n">update</span><span class="p">(</span><span class="n">input_activations</span><span class="p">,</span> <span class="n">learned_activations</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">encoder_weight_reference</span><span class="p">)</span></code>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ActivationResampler.update" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Update the collated data from forward passes.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>input_activations</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.INPUT_OUTPUT_FEATURE">INPUT_OUTPUT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Input activations to the SAE.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>learned_activations</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.LEARNT_FEATURE" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.LEARNT_FEATURE">LEARNT_FEATURE</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Learned activations from the SAE.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>loss</code></td>
          <td>
                <code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.names" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.names">names</a>(<a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.BATCH" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.BATCH">BATCH</a>, <a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL" href="../../tensor_types/#sparse_autoencoder.tensor_types.Axis.COMPONENT_OPTIONAL">COMPONENT_OPTIONAL</a>)]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Loss per input activation.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>encoder_weight_reference</code></td>
          <td>
                <code><span title="torch.nn.Parameter">Parameter</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Reference to the SAE encoder weight tensor.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>TypeError</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If the loss or input activations are not lists (e.g. from unsync having not
been called).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">update</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">learned_activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">loss</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">)],</span>
    <span class="n">encoder_weight_reference</span><span class="p">:</span> <span class="n">Parameter</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Update the collated data from forward passes.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_activations: Input activations to the SAE.</span>
<span class="sd">        learned_activations: Learned activations from the SAE.</span>
<span class="sd">        loss: Loss per input activation.</span>
<span class="sd">        encoder_weight_reference: Reference to the SAE encoder weight tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the loss or input activations are not lists (e.g. from unsync having not</span>
<span class="sd">            been called).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_collecting_neuron_activity_process</span><span class="p">:</span>
        <span class="n">neuron_has_fired</span><span class="p">:</span> <span class="n">Bool</span><span class="p">[</span>
            <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">BATCH</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">COMPONENT_OPTIONAL</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE</span><span class="p">)</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">learned_activations</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neuron_fired_count</span> <span class="o">+=</span> <span class="n">neuron_has_fired</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_collecting_loss_process</span><span class="p">:</span>
        <span class="c1"># Typecast</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_activations</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span>

        <span class="c1"># Append</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_activations</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_n_activations_seen_process</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">learned_activations</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_encoder_weight</span> <span class="o">=</span> <span class="n">encoder_weight_reference</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>          <code>ParameterUpdateResults</code>

  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults" class="headerlink" title="Permanent link"></a></h2>


  <div class="doc doc-contents ">

  
      <p>Parameter update results from resampling dead neurons.</p>

            <details class="quote">
              <summary>Source code in <code>sparse_autoencoder/activation_resampler/activation_resampler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ParameterUpdateResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parameter update results from resampling dead neurons.&quot;&quot;&quot;</span>

    <span class="n">dead_neuron_indices</span><span class="p">:</span> <span class="n">Int</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE_IDX</span><span class="p">]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dead neuron indices.&quot;&quot;&quot;</span>

    <span class="n">dead_encoder_weight_updates</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)</span>
    <span class="p">]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dead encoder weight updates.&quot;&quot;&quot;</span>

    <span class="n">dead_encoder_bias_updates</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dead encoder bias updates.&quot;&quot;&quot;</span>

    <span class="n">dead_decoder_weight_updates</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span>
        <span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">)</span>
    <span class="p">]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dead decoder weight updates.&quot;&quot;&quot;</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_decoder_weight_updates" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>          <code class="highlight language-python"><span class="n">dead_decoder_weight_updates</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">)]</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_decoder_weight_updates" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Dead decoder weight updates.</p>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_encoder_bias_updates" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>          <code class="highlight language-python"><span class="n">dead_encoder_bias_updates</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">]</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_encoder_bias_updates" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Dead encoder bias updates.</p>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_encoder_weight_updates" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>          <code class="highlight language-python"><span class="n">dead_encoder_weight_updates</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">names</span><span class="p">(</span><span class="n">Axis</span><span class="o">.</span><span class="n">DEAD_FEATURE</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">INPUT_OUTPUT_FEATURE</span><span class="p">)]</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_encoder_weight_updates" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Dead encoder weight updates.</p>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_neuron_indices" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>          <code class="highlight language-python"><span class="n">dead_neuron_indices</span><span class="p">:</span> <span class="n">Int</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Axis</span><span class="o">.</span><span class="n">LEARNT_FEATURE_IDX</span><span class="p">]</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#sparse_autoencoder.activation_resampler.activation_resampler.ParameterUpdateResults.dead_neuron_indices" class="headerlink" title="Permanent link"></a></h3>


  <div class="doc doc-contents ">
  
      <p>Dead neuron indices.</p>
  </div>

</div>





  </div>

  </div>


</div>




  </div>

  </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.action.edit"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e1c3ead8.min.js"></script>
      
        <script src="../../../javascript/custom_formatting.js"></script>
      
        <script src="../../../javascript/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>